{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6qruq9ZFQsN"
   },
   "source": [
    "# Further Pre-training MobileBERT MLM with Centralized Training (Shakespeare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2833,
     "status": "ok",
     "timestamp": 1606087549099,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "-AgOn_qCFQsk"
   },
   "outputs": [],
   "source": [
    "# Copyright 2020, The TensorFlow Federated Authors.\n",
    "# Copyright 2020, Ronald Seoh\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zUGmvEbFQts"
   },
   "source": [
    "## Google Colab settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60818,
     "status": "ok",
     "timestamp": 1606087607198,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "_1nBG9qaFQt9",
    "outputId": "a25b3ce7-ffd4-4e42-9074-11951bb0de02"
   },
   "outputs": [],
   "source": [
    "# Use Google Colab\n",
    "use_colab = True\n",
    "\n",
    "# Is this notebook running on Colab?\n",
    "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
    "# should be available in this environment\n",
    "\n",
    "# Previous version used importlib, but we could do the same thing with\n",
    "# just attempting to import google.colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab_available = True\n",
    "except:\n",
    "    colab_available = False\n",
    "\n",
    "if use_colab and colab_available:\n",
    "    # Mount Google Drive root directory\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # cd to the appropriate working directory under my Google Drive\n",
    "    %cd '/content/drive/My Drive/Colab Notebooks/BERTerated'\n",
    "    \n",
    "    # List the directory contents\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Multi GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 60704,
     "status": "ok",
     "timestamp": 1606087607211,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "8sfNa8t-TPwZ"
   },
   "outputs": [],
   "source": [
    "# IPython reloading magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 141262,
     "status": "ok",
     "timestamp": 1606087687915,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "seTmBYc5EJ7q",
    "outputId": "4d277950-8fc8-4a70-abe7-4c67dcd3d411"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F16eB2w-FQuw"
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 150721,
     "status": "ok",
     "timestamp": 1606087697501,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "k_SnruV2FQu0",
    "outputId": "ac3740c1-8d76-4d10-ec4f-7c608fc78568"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:43: UserWarning: You are currently using a nightly version of TensorFlow (2.5.0-dev20201121). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'Hello, World!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import datetime\n",
    "import json\n",
    "import pathlib\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import tensorflow_text as tf_text\n",
    "import transformers\n",
    "import tqdm\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import fedavg\n",
    "import fedavg_client\n",
    "import datasets\n",
    "import utils\n",
    "\n",
    "# Random seed settings\n",
    "random_seed = 692\n",
    "random.seed(random_seed) # Python\n",
    "np.random.seed(random_seed) # NumPy\n",
    "tf.random.set_seed(random_seed) # TensorFlow\n",
    "\n",
    "# Tensorflow GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Test if TFF is working\n",
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 150582,
     "status": "ok",
     "timestamp": 1606087697533,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "FHYxELiQFQvI",
    "outputId": "cb6b86b8-8309-4968-95cc-40400f7bfcac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.9 (default, Oct  8 2020, 12:12:24) \n",
      "[GCC 8.4.0]\n",
      "NumPy version: 1.18.4\n",
      "TensorFlow version: 2.5.0-dev20201121\n",
      "TensorFlow Federated version: 0.17.0\n",
      "Transformers version: 3.4.0\n"
     ]
    }
   ],
   "source": [
    "# Print version information\n",
    "print(\"Python version: \" + sys.version)\n",
    "print(\"NumPy version: \" + np.__version__)\n",
    "print(\"TensorFlow version: \" + tf.__version__)\n",
    "print(\"TensorFlow Federated version: \" + tff.__version__)\n",
    "print(\"Transformers version: \" + transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 150441,
     "status": "ok",
     "timestamp": 1606087697569,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "sLvpOpvhEA0E",
    "outputId": "02b60b7d-a25c-4714-94cc-9dc3e2ac1d95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 23 05:11:32 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.57       Driver Version: 450.57       CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:03:00.0  On |                  N/A |\r\n",
      "|  0%   25C    P2    46W / 250W |  10393MiB / 11018MiB |      1%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:04:00.0 Off |                  N/A |\r\n",
      "|  0%   22C    P8     1W / 250W |      1MiB / 11019MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYXMEboAFQvd"
   },
   "source": [
    "## Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 150382,
     "status": "ok",
     "timestamp": 1606087697586,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "M071lqOQFQvi"
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_CONFIG = {}\n",
    "\n",
    "EXPERIMENT_CONFIG['HUGGINGFACE_MODEL_NAME'] = 'google/mobilebert-uncased'\n",
    "EXPERIMENT_CONFIG['HUGGINGFACE_CACHE_DIR'] = os.path.join('.', 'transformers_cache')\n",
    "\n",
    "EXPERIMENT_CONFIG['CENTRALIZED_EPOCHS'] = 9\n",
    "EXPERIMENT_CONFIG['VALIDATION_FREQUENCY'] = 3\n",
    "\n",
    "EXPERIMENT_CONFIG['BATCH_SIZE'] = 32\n",
    "EXPERIMENT_CONFIG['TEST_BATCH_SIZE'] = 64\n",
    "\n",
    "EXPERIMENT_CONFIG['BERT_MAX_SEQ_LENGTH'] = 128\n",
    "\n",
    "EXPERIMENT_CONFIG['CENTRALIZED_LEARNING_RATE'] = [5e-5, 3e-5, 2e-5]\n",
    "\n",
    "EXPERIMENT_CONFIG['TRAIN_NUM_CLIENT_LIMIT'] = -1\n",
    "EXPERIMENT_CONFIG['TEST_NUM_CLIENT_LIMIT'] = -1\n",
    "\n",
    "EXPERIMENT_CONFIG['RESULTS_DIRECTORY'] = os.path.join(\n",
    "    '.', 'results',\n",
    "    'mobilebert_mlm_shakespeare_centralized',\n",
    "    datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    ")\n",
    "\n",
    "EXPERIMENT_CONFIG['RESULTS_LOG'] = os.path.join(EXPERIMENT_CONFIG['RESULTS_DIRECTORY'], \"logs\")\n",
    "EXPERIMENT_CONFIG['RESULTS_MODEL'] = os.path.join(EXPERIMENT_CONFIG['RESULTS_DIRECTORY'], \"model\")\n",
    "EXPERIMENT_CONFIG['RESULTS_CONFIG'] = os.path.join(EXPERIMENT_CONFIG['RESULTS_DIRECTORY'], \"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 150344,
     "status": "ok",
     "timestamp": 1606087697607,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "lWVIjOBXTPwh"
   },
   "outputs": [],
   "source": [
    "# Dump all the configuration into a json file\n",
    "pathlib.Path(EXPERIMENT_CONFIG['RESULTS_CONFIG']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(EXPERIMENT_CONFIG['RESULTS_CONFIG'], \"config.json\"), 'w') as config_file:\n",
    "    json.dump(EXPERIMENT_CONFIG, config_file, indent=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-tHcHX0FQvz"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuI6ktSIbCjk"
   },
   "source": [
    "### Dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 152243,
     "status": "ok",
     "timestamp": 1606087699586,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "cVkK1BV9FQv3"
   },
   "outputs": [],
   "source": [
    "train_client_data, test_client_data = tff.simulation.datasets.shakespeare.load_data(cache_dir='./tff_cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNYlFQJ3Wt1O"
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 152797,
     "status": "ok",
     "timestamp": 1606087700213,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "ZXmJYQbeFQwG"
   },
   "outputs": [],
   "source": [
    "bert_tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    EXPERIMENT_CONFIG['HUGGINGFACE_MODEL_NAME'], cache_dir=EXPERIMENT_CONFIG['HUGGINGFACE_CACHE_DIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 152764,
     "status": "ok",
     "timestamp": 1606087700218,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "8c7S9s9qRlsi"
   },
   "outputs": [],
   "source": [
    "# Imitate transformers tokenizer with TF.Text Tokenizer\n",
    "tokenizer_tf_text, vocab_lookup_table, special_ids_mask_table = \\\n",
    "datasets.preprocessing_for_bert.convert_huggingface_tokenizer(bert_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sfMNvpmFQwW"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 1348,
     "status": "ok",
     "timestamp": 1606087747560,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "oIOw1zG1RfnU"
   },
   "outputs": [],
   "source": [
    "def check_empty_snippet(x):\n",
    "    return tf.strings.length(x['snippets']) > 0\n",
    "\n",
    "def tokenizer_and_mask_wrapped(x):\n",
    "\n",
    "    masked, labels = datasets.preprocessing_for_bert.tokenize_and_mask(tf.reshape(x['snippets'], shape=[1]),\n",
    "                                                                       max_seq_length=EXPERIMENT_CONFIG['BERT_MAX_SEQ_LENGTH'],\n",
    "                                                                       bert_tokenizer_tf_text=tokenizer_tf_text,\n",
    "                                                                       vocab_lookup_table=vocab_lookup_table,\n",
    "                                                                       special_ids_mask_table=special_ids_mask_table,\n",
    "                                                                       cls_token_id=bert_tokenizer.cls_token_id,\n",
    "                                                                       sep_token_id=bert_tokenizer.sep_token_id,\n",
    "                                                                       pad_token_id=bert_tokenizer.pad_token_id,\n",
    "                                                                       mask_token_id=bert_tokenizer.mask_token_id)\n",
    "\n",
    "    return (masked, labels)\n",
    "\n",
    "def preprocess_for_train(train_dataset):\n",
    "    return (\n",
    "        train_dataset\n",
    "        # Tokenize each samples using MobileBERT tokenizer\n",
    "        .map(tokenizer_and_mask_wrapped, num_parallel_calls=tf.data.experimental.AUTOTUNE, deterministic=False)\n",
    "        # Shuffle\n",
    "        .shuffle(100000)\n",
    "        # Form minibatches\n",
    "        # Use drop_remainder=True to force the batch size to be exactly BATCH_SIZE\n",
    "        # and make the shape **exactly** (BATCH_SIZE, SEQ_LENGTH)\n",
    "        .batch(EXPERIMENT_CONFIG['BATCH_SIZE'])\n",
    "        # Repeat to make each client train multiple epochs\n",
    "        # NOTE: THIS SHOULD BE COMMENTED OUT FOR CENTRALIZED TRAINING\n",
    "        #.repeat(count=EXPERIMENT_CONFIG['CENTRALIZED_EPOCHS'])\n",
    "    )\n",
    "    \n",
    "def preprocess_for_test(test_dataset):\n",
    "    return (\n",
    "        test_dataset\n",
    "        # Tokenize each samples using MobileBERT tokenizer\n",
    "        .map(tokenizer_and_mask_wrapped, num_parallel_calls=tf.data.experimental.AUTOTUNE, deterministic=False)\n",
    "        # Shuffle\n",
    "        .shuffle(100000)\n",
    "        # Form minibatches\n",
    "        # Use drop_remainder=True to force the batch size to be exactly TEST_BATCH_SIZE\n",
    "        # and make the shape **exactly** (TEST_BATCH_SIZE, SEQ_LENGTH)\n",
    "        .batch(EXPERIMENT_CONFIG['TEST_BATCH_SIZE'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keEsPDMXTPwi"
   },
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 152686,
     "status": "ok",
     "timestamp": 1606087700226,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "XkFnSQDbTPwi"
   },
   "outputs": [],
   "source": [
    "# Since the dataset is pretty large, we randomly select TRAIN_NUM_CLIENT_LIMIT number of clients.\n",
    "all_train_client_ids = train_client_data.client_ids\n",
    "\n",
    "random.shuffle(all_train_client_ids)\n",
    "\n",
    "if EXPERIMENT_CONFIG['TRAIN_NUM_CLIENT_LIMIT'] > 0:\n",
    "    selected_train_client_ids = all_train_client_ids[0:EXPERIMENT_CONFIG['TRAIN_NUM_CLIENT_LIMIT']]\n",
    "else:\n",
    "    selected_train_client_ids = all_train_client_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 156482,
     "status": "ok",
     "timestamp": 1606087704059,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "meLGsVyoiW7u"
   },
   "outputs": [],
   "source": [
    "train_client_data_all_merged = None\n",
    "train_client_data_all_merged_length = 0\n",
    "\n",
    "for i in tqdm.notebook.tqdm(range(len(selected_train_client_ids))):\n",
    "    # Get the current client dataset while filtering out empty data points\n",
    "    current_client_data = train_client_data.create_tf_dataset_for_client(selected_train_client_ids[i]).filter(check_empty_snippet)\n",
    "\n",
    "    # How many data points in this client's dataset?\n",
    "    # Apparently iterating through each of them is the only way to get the lengths of tf.data.Dataset\n",
    "    # This is not very cool tbh.\n",
    "    for _ in tqdm.notebook.tqdm(current_client_data, leave=False):\n",
    "        train_client_data_all_merged_length = train_client_data_all_merged_length + 1 \n",
    "\n",
    "    if train_client_data_all_merged is None:\n",
    "        train_client_data_all_merged = current_client_data\n",
    "    else:\n",
    "        train_client_data_all_merged = train_client_data_all_merged.concatenate(current_client_data)\n",
    "        \n",
    "print(len(selected_train_client_ids), \"train clients processed.\")\n",
    "print(train_client_data_all_merged_length, \"train data points available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many training steps will be there?\n",
    "num_training_steps = math.ceil(train_client_data_all_merged_length / EXPERIMENT_CONFIG['BATCH_SIZE'])\n",
    "print(\"There will be\", num_training_steps, \"training steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3099,
     "status": "ok",
     "timestamp": 1606087763190,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "J8LRq17RMw_f",
    "outputId": "4bb955be-ccd6-4649-a647-8a91f03fdfb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:478: Bernoulli.__init__ (from tensorflow.python.ops.distributions.bernoulli) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:478: Bernoulli.__init__ (from tensorflow.python.ops.distributions.bernoulli) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/bernoulli.py:97: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/bernoulli.py:97: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "train_client_data_all_merged = preprocess_for_train(train_client_data_all_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1395,
     "status": "ok",
     "timestamp": 1606087766289,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "Whby0nVGMytH",
    "outputId": "d656aca5-2b31-48fe-8710-330afca61e41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 128), dtype=tf.int32, name=None), TensorSpec(shape=(None, 128), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "print(train_client_data_all_merged.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6JzjvYsTPwj"
   },
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 1613,
     "status": "ok",
     "timestamp": 1606087771275,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "SXvciKeuTPwj"
   },
   "outputs": [],
   "source": [
    "# Since the stackoverflow dataset is pretty large, we randomly select TEST_NUM_CLIENT_LIMIT number of clients.\n",
    "all_test_client_ids = test_client_data.client_ids\n",
    "\n",
    "random.shuffle(all_test_client_ids)\n",
    "\n",
    "if EXPERIMENT_CONFIG['TEST_NUM_CLIENT_LIMIT'] > 0:\n",
    "    selected_test_client_ids = all_test_client_ids[0:EXPERIMENT_CONFIG['TEST_NUM_CLIENT_LIMIT']]\n",
    "else:\n",
    "    selected_test_client_ids = all_test_client_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 5325,
     "status": "ok",
     "timestamp": 1606087779567,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "-X8beaHakOge"
   },
   "outputs": [],
   "source": [
    "test_client_data_all_merged = None\n",
    "test_client_data_all_merged_length = 0\n",
    "\n",
    "for i in tqdm.notebook.tqdm(range(len(selected_test_client_ids))):\n",
    "    # Get the current client dataset while filtering out empty data points\n",
    "    current_client_data = test_client_data.create_tf_dataset_for_client(selected_test_client_ids[i]).filter(check_empty_snippet)\n",
    "\n",
    "    # How many data points in this client's dataset?\n",
    "    # Apparently iterating through each of them is the only way to get the lengths of tf.data.Dataset\n",
    "    # This is not very cool tbh.\n",
    "    for _ in tqdm.notebook.tqdm(current_client_data, leave=False):\n",
    "        test_client_data_all_merged_length = test_client_data_all_merged_length + 1 \n",
    "\n",
    "    if test_client_data_all_merged is None:\n",
    "        test_client_data_all_merged = current_client_data\n",
    "    else:\n",
    "        test_client_data_all_merged = test_client_data_all_merged.concatenate(current_client_data)\n",
    "        \n",
    "print(len(selected_test_client_ids), \"train clients processed.\")\n",
    "print(test_client_data_all_merged_length, \"train data points available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 3929,
     "status": "ok",
     "timestamp": 1606087786149,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "Wj_jUe1MnVpx"
   },
   "outputs": [],
   "source": [
    "test_client_data_all_merged = preprocess_for_test(test_client_data_all_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1447,
     "status": "ok",
     "timestamp": 1606087788968,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "QtRWktqVTPwk",
    "outputId": "7fd2d0bc-431c-49a3-d0dd-5824f70c2606"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 128), dtype=tf.int32, name=None), TensorSpec(shape=(None, 128), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "print(test_client_data_all_merged.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_o5NZpuzFQw7"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7579,
     "status": "ok",
     "timestamp": 1606087802548,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "kfTDbXNpnr1A",
    "outputId": "67cfd9a6-e7c8-4d61-ac81-344f160f99bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFMobileBertForPreTraining.\n",
      "\n",
      "All the layers of TFMobileBertForPreTraining were initialized from the model checkpoint at google/mobilebert-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMobileBertForPreTraining for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_model = transformers.TFAutoModelForPreTraining.from_pretrained(\n",
    "    EXPERIMENT_CONFIG['HUGGINGFACE_MODEL_NAME'], cache_dir=EXPERIMENT_CONFIG['HUGGINGFACE_CACHE_DIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1501,
     "status": "ok",
     "timestamp": 1606087806092,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "4xrKChglOi9J",
    "outputId": "00226287-b1f9-4eed-8c72-8310ef29b622"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileBertConfig {\n",
      "  \"_name_or_path\": \"google/mobilebert-uncased\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_activation\": false,\n",
      "  \"embedding_size\": 128,\n",
      "  \"hidden_act\": \"relu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"intra_bottleneck_size\": 128,\n",
      "  \"key_query_shared_bottleneck\": true,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"mobilebert\",\n",
      "  \"normalization_type\": \"no_norm\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_feedforward_networks\": 4,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"trigram_input\": true,\n",
      "  \"true_hidden_size\": 128,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bottleneck\": true,\n",
      "  \"use_bottleneck_attention\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bert_model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 9430,
     "status": "ok",
     "timestamp": 1606087831104,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "EfpJ2o3Z90J8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:5047: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:5047: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Generate a new model with pretrained weights\n",
    "# Due to the limitations with Keras subclasses,\n",
    "# we can only use the main layer part from pretrained models\n",
    "# and add output heads by ourselves\n",
    "bert_keras_converted = utils.convert_huggingface_mlm_to_keras(\n",
    "    huggingface_model=bert_model,\n",
    "    max_seq_length=EXPERIMENT_CONFIG['BERT_MAX_SEQ_LENGTH'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1577,
     "status": "ok",
     "timestamp": 1606087840031,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "u8YTb2lN92jr",
    "outputId": "3665e662-ece2-4ab9-f076-0e7e2a44a9f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "mobilebert (TFMobileBertMain ((None, 128, 512), (None, 24581888  \n",
      "_________________________________________________________________\n",
      "standalone_tf_mobile_bert_ml (None, 128, 30522)        15921466  \n",
      "=================================================================\n",
      "Total params: 40,503,354\n",
      "Trainable params: 40,503,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_keras_converted.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qM6T_Mp8FQxQ"
   },
   "source": [
    "## Training / Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "executionInfo": {
     "elapsed": 173014,
     "status": "error",
     "timestamp": 1606088241521,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "oqCXFc7gFQxl",
    "outputId": "45eeb5be-ed1f-408c-f01a-4e35928668e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "Running 0.0000500\n",
      "Epoch 1/9\n",
      "498/498 [==============================] - 236s 345ms/step - loss: 4.0593\n",
      "Epoch 2/9\n",
      "498/498 [==============================] - 174s 335ms/step - loss: 3.6096\n",
      "Epoch 3/9\n",
      "498/498 [==============================] - 202s 392ms/step - loss: 3.6162 - val_loss: 3.5706\n",
      "Epoch 4/9\n",
      "498/498 [==============================] - 178s 344ms/step - loss: 3.6176\n",
      "Epoch 5/9\n",
      "498/498 [==============================] - 178s 342ms/step - loss: 3.6095\n",
      "Epoch 6/9\n",
      "498/498 [==============================] - 192s 372ms/step - loss: 3.6406 - val_loss: 3.5849\n",
      "Epoch 7/9\n",
      "498/498 [==============================] - 178s 343ms/step - loss: 3.5937\n",
      "Epoch 8/9\n",
      "498/498 [==============================] - 179s 346ms/step - loss: 3.6111\n",
      "Epoch 9/9\n",
      "498/498 [==============================] - 195s 378ms/step - loss: 3.6119 - val_loss: 3.6123\n",
      "37/37 [==============================] - 15s 215ms/step - loss: 3.5726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 5340). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./results/mobilebert_mlm_shakespeare_centralized/20201123-051133/model/0.0000500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./results/mobilebert_mlm_shakespeare_centralized/20201123-051133/model/0.0000500/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "Running 0.0000300\n",
      "Epoch 1/9\n",
      "498/498 [==============================] - 260s 357ms/step - loss: 4.1042\n",
      "Epoch 2/9\n",
      "498/498 [==============================] - 176s 339ms/step - loss: 3.6767\n",
      "Epoch 3/9\n",
      "498/498 [==============================] - 206s 398ms/step - loss: 3.7181 - val_loss: 3.6481\n",
      "Epoch 4/9\n",
      "498/498 [==============================] - 176s 339ms/step - loss: 3.6807\n",
      "Epoch 5/9\n",
      "498/498 [==============================] - 176s 340ms/step - loss: 3.7116\n",
      "Epoch 6/9\n",
      "498/498 [==============================] - 191s 370ms/step - loss: 3.7107 - val_loss: 3.6949\n",
      "Epoch 7/9\n",
      "498/498 [==============================] - 177s 340ms/step - loss: 3.7012\n",
      "Epoch 8/9\n",
      "498/498 [==============================] - 177s 342ms/step - loss: 3.6932\n",
      "Epoch 9/9\n",
      "498/498 [==============================] - 192s 370ms/step - loss: 3.7208 - val_loss: 3.6316\n",
      "37/37 [==============================] - 15s 213ms/step - loss: 3.6424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 5340). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./results/mobilebert_mlm_shakespeare_centralized/20201123-051133/model/0.0000300/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./results/mobilebert_mlm_shakespeare_centralized/20201123-051133/model/0.0000300/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "Running 0.0000200\n",
      "Epoch 1/9\n",
      "498/498 [==============================] - 257s 358ms/step - loss: 4.1720\n",
      "Epoch 2/9\n",
      "498/498 [==============================] - 177s 341ms/step - loss: 3.7994\n",
      "Epoch 3/9\n",
      "498/498 [==============================] - 209s 405ms/step - loss: 3.7769 - val_loss: 3.6898\n",
      "Epoch 4/9\n",
      "498/498 [==============================] - 178s 343ms/step - loss: 3.7857\n",
      "Epoch 5/9\n",
      "498/498 [==============================] - 179s 343ms/step - loss: 3.8040\n",
      "Epoch 6/9\n",
      "498/498 [==============================] - 194s 374ms/step - loss: 3.7809 - val_loss: 3.6897\n",
      "Epoch 7/9\n",
      "498/498 [==============================] - 179s 344ms/step - loss: 3.7910\n",
      "Epoch 8/9\n",
      "498/498 [==============================] - 178s 344ms/step - loss: 3.7938\n",
      "Epoch 9/9\n",
      "498/498 [==============================] - 193s 373ms/step - loss: 3.7728 - val_loss: 3.7204\n",
      "37/37 [==============================] - 15s 214ms/step - loss: 3.7338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 5340). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./results/mobilebert_mlm_shakespeare_centralized/20201123-051133/model/0.0000200/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./results/mobilebert_mlm_shakespeare_centralized/20201123-051133/model/0.0000200/assets\n"
     ]
    }
   ],
   "source": [
    "for lr in EXPERIMENT_CONFIG['CENTRALIZED_LEARNING_RATE']:  \n",
    "    config_name = \"%.7f\" % (lr)\n",
    "    logdir = os.path.join(EXPERIMENT_CONFIG['RESULTS_LOG'], config_name)\n",
    "    \n",
    "    print(\"----\")\n",
    "    print(\"Running\", config_name)\n",
    "\n",
    "    # A fresh copy of the model for the current config\n",
    "    bert_keras_converted_cloned = tf.keras.models.clone_model(bert_keras_converted)\n",
    "\n",
    "    # Always start with the pretrained weights\n",
    "    bert_keras_converted_cloned.set_weights(bert_keras_converted.get_weights())\n",
    "    \n",
    "    # Optimizer\n",
    "    adamw_optimizer, lr_schedule = transformers.create_optimizer(\n",
    "        init_lr=lr,\n",
    "        num_train_steps=num_training_steps,\n",
    "        num_warmup_steps=num_training_steps * (2/5),\n",
    "        weight_decay_rate=0.01,\n",
    "    )\n",
    "\n",
    "    bert_keras_converted_cloned.compile(\n",
    "        optimizer=adamw_optimizer,\n",
    "        loss=utils.MaskedLMCrossEntropy(),\n",
    "    )\n",
    "\n",
    "    bert_keras_converted_cloned.fit(\n",
    "        train_client_data_all_merged,\n",
    "        epochs=EXPERIMENT_CONFIG['CENTRALIZED_EPOCHS'],\n",
    "        validation_data=test_client_data_all_merged,\n",
    "        validation_freq=EXPERIMENT_CONFIG['VALIDATION_FREQUENCY'],\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.TensorBoard(logdir),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    bert_keras_converted_cloned.evaluate(test_client_data_all_merged)\n",
    "\n",
    "    # Save the trained model for the current configuartion\n",
    "    bert_keras_converted_cloned.save(\n",
    "        os.path.join(EXPERIMENT_CONFIG['RESULTS_MODEL'], config_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mobilebert_mlm_shakespeare_centralized.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "375px",
    "width": "636px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
