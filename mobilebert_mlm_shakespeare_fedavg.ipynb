{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6qruq9ZFQsN"
   },
   "source": [
    "# Further Pre-training MobileBERT MLM with Federated Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2018,
     "status": "ok",
     "timestamp": 1605671629554,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "-AgOn_qCFQsk"
   },
   "outputs": [],
   "source": [
    "# Copyright 2020, The TensorFlow Federated Authors.\n",
    "# Copyright 2020, Ronald Seoh\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zUGmvEbFQts"
   },
   "source": [
    "## Google Colab settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51337,
     "status": "ok",
     "timestamp": 1605671678901,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "_1nBG9qaFQt9",
    "outputId": "d9155a26-a6c9-4598-9226-1f9fa4e41eb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-federated==0.17.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/54/900d99d3cff21b6a570281b51f4878a745c0eece7732bb7fc26eee61ef57/tensorflow_federated-0.17.0-py2.py3-none-any.whl (517kB)\n",
      "\u001b[K     |████████████████████████████████| 522kB 7.8MB/s \n",
      "\u001b[?25hCollecting tensorflow-text==2.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/b2/2dbd90b93913afd07e6101b8b84327c401c394e60141c1e98590038060b3/tensorflow_text-2.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.6MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6MB 14.1MB/s \n",
      "\u001b[?25hCollecting transformers==3.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 43.7MB/s \n",
      "\u001b[?25hCollecting tensorflow-addons~=0.11.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/f8/d6fca180c123f2851035c4493690662ebdad0849a9059d56035434bff5c9/tensorflow_addons-0.11.2-cp36-cp36m-manylinux2010_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 31.0MB/s \n",
      "\u001b[?25hCollecting absl-py~=0.9.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 55.3MB/s \n",
      "\u001b[?25hCollecting attrs~=19.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/db/4313ab3be961f7a763066401fb77f7748373b6094076ae2bda2806988af6/attrs-19.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy~=1.18.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0) (1.18.5)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0) (0.1.5)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0) (2.10.0)\n",
      "Collecting tensorflow-model-optimization~=0.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/cc/4b0831f492396f03a4563cc749ad94cbf7af986aaa7a7d89e5979029ce5c/tensorflow_model_optimization-0.4.1-py2.py3-none-any.whl (172kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 50.7MB/s \n",
      "\u001b[?25hCollecting tensorflow-privacy~=0.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/ae/7db0dcf76a746314a174578a7b99ff098b40b908c4c693a955a2bbc0127b/tensorflow_privacy-0.5.1-py3-none-any.whl (149kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 54.3MB/s \n",
      "\u001b[?25hCollecting grpcio~=1.29.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/04/2b67f0a3645481235d5547891fd0e45e384f1ae5676788f24a7c8735b4e9/grpcio-1.29.0-cp36-cp36m-manylinux2010_x86_64.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 53.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: portpicker~=1.3.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0) (1.3.1)\n",
      "Collecting semantic-version~=2.8.5\n",
      "  Downloading https://files.pythonhosted.org/packages/a5/15/00ef3b7888a10363b7c402350eda3acf395ff05bebae312d1296e528516a/semantic_version-2.8.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: retrying~=1.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0) (1.3.3)\n",
      "Requirement already satisfied: tensorflow~=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0) (2.3.0)\n",
      "Collecting cachetools~=3.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2.23.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.12.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.0.12)\n",
      "Collecting tokenizers==0.9.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 59.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (20.4)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 55.9MB/s \n",
      "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 51.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (4.41.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons~=0.11.1->tensorflow-federated==0.17.0) (2.7.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py~=0.9.0->tensorflow-federated==0.17.0) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-privacy~=0.5.0->tensorflow-federated==0.17.0) (2.3.0)\n",
      "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from tensorflow-privacy~=0.5.0->tensorflow-federated==0.17.0) (1.4.1)\n",
      "Requirement already satisfied: mpmath in /usr/local/lib/python3.6/dist-packages (from tensorflow-privacy~=0.5.0->tensorflow-federated==0.17.0) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (1.1.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (0.35.1)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (2.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (0.2.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (1.1.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (0.3.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (1.24.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.4.0) (50.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.4.0) (2.4.7)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (0.17.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (0.4.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (1.17.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (3.3.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (1.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (0.2.8)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (3.4.0)\n",
      "Building wheels for collected packages: absl-py, sacremoses\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for absl-py: filename=absl_py-0.9.0-cp36-none-any.whl size=121933 sha256=e34ef4f4123368d409be0d3e3633f62ce72ba419f8a3feaeb1b95033e4ed3d0a\n",
      "  Stored in directory: /root/.cache/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=8dd186e98ff1c7b891594eadd150533677ebc64884780730c3a480793cf25600\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built absl-py sacremoses\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorflow-addons, absl-py, attrs, tensorflow-model-optimization, tensorflow-privacy, grpcio, semantic-version, cachetools, tensorflow-federated, tensorflow-text, tokenizers, sacremoses, sentencepiece, transformers\n",
      "  Found existing installation: tensorflow-addons 0.8.3\n",
      "    Uninstalling tensorflow-addons-0.8.3:\n",
      "      Successfully uninstalled tensorflow-addons-0.8.3\n",
      "  Found existing installation: absl-py 0.10.0\n",
      "    Uninstalling absl-py-0.10.0:\n",
      "      Successfully uninstalled absl-py-0.10.0\n",
      "  Found existing installation: attrs 20.2.0\n",
      "    Uninstalling attrs-20.2.0:\n",
      "      Successfully uninstalled attrs-20.2.0\n",
      "  Found existing installation: tensorflow-privacy 0.2.2\n",
      "    Uninstalling tensorflow-privacy-0.2.2:\n",
      "      Successfully uninstalled tensorflow-privacy-0.2.2\n",
      "  Found existing installation: grpcio 1.33.2\n",
      "    Uninstalling grpcio-1.33.2:\n",
      "      Successfully uninstalled grpcio-1.33.2\n",
      "  Found existing installation: cachetools 4.1.1\n",
      "    Uninstalling cachetools-4.1.1:\n",
      "      Successfully uninstalled cachetools-4.1.1\n",
      "Successfully installed absl-py-0.9.0 attrs-19.3.0 cachetools-3.1.1 grpcio-1.29.0 sacremoses-0.0.43 semantic-version-2.8.5 sentencepiece-0.1.94 tensorflow-addons-0.11.2 tensorflow-federated-0.17.0 tensorflow-model-optimization-0.4.1 tensorflow-privacy-0.5.1 tensorflow-text-2.3.0 tokenizers-0.9.2 transformers-3.4.0\n",
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/Colab Notebooks/BERTerated\n",
      "fedavg_client.py\t\t\t   __pycache__\n",
      "fedavg.py\t\t\t\t   README.md\n",
      "huggingface_keras_layers.py\t\t   tff_cache\n",
      "LICENSE\t\t\t\t\t   transformers_cache\n",
      "mobilebert_mlm_shakespeare_fedavg.ipynb    utils.py\n",
      "mobilebert_mlm_stackoverflow_fedavg.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Use Google Colab\n",
    "use_colab = True\n",
    "\n",
    "# Is this notebook running on Colab?\n",
    "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
    "# should be available in this environment\n",
    "\n",
    "# Previous version used importlib, but we could do the same thing with\n",
    "# just attempting to import google.colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab_available = True\n",
    "except:\n",
    "    colab_available = False\n",
    "\n",
    "if use_colab and colab_available:\n",
    "    # Mount Google Drive root directory\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # cd to the appropriate working directory under my Google Drive\n",
    "    %cd '/content/drive/My Drive/Colab Notebooks/BERTerated'\n",
    "    \n",
    "    # List the directory contents\n",
    "    !ls\n",
    "\n",
    "# IPython reloading magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F16eB2w-FQuw"
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63294,
     "status": "ok",
     "timestamp": 1605671690886,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "k_SnruV2FQu0",
    "outputId": "3ae7e4be-bf77-4fdc-e5ff-8046c94d1e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'Hello, World!'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import tensorflow_text as tf_text\n",
    "import transformers\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import fedavg\n",
    "import fedavg_client\n",
    "import utils\n",
    "\n",
    "# Random seed settings\n",
    "random_seed = 692\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "# Tensorflow GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Test the TFF is working:\n",
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63279,
     "status": "ok",
     "timestamp": 1605671690898,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "FHYxELiQFQvI",
    "outputId": "965b3251-5f89-4f60-8429-a86430b8c313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.9 (default, Oct  8 2020, 12:12:24) \n",
      "[GCC 8.4.0]\n",
      "NumPy version: 1.18.5\n",
      "TensorFlow version: 2.3.0\n",
      "TensorFlow Federated version: 0.17.0\n",
      "Transformers version: 3.4.0\n"
     ]
    }
   ],
   "source": [
    "# Print version information\n",
    "print(\"Python version: \" + sys.version)\n",
    "print(\"NumPy version: \" + np.__version__)\n",
    "print(\"TensorFlow version: \" + tf.__version__)\n",
    "print(\"TensorFlow Federated version: \" + tff.__version__)\n",
    "print(\"Transformers version: \" + transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYXMEboAFQvd"
   },
   "source": [
    "## Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 63259,
     "status": "ok",
     "timestamp": 1605671690902,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "M071lqOQFQvi"
   },
   "outputs": [],
   "source": [
    "TOTAL_ROUNDS = 2 # Number of total training rounds\n",
    "ROUNDS_PER_EVAL = 1 # How often to evaluate\n",
    "\n",
    "TRAIN_CLIENTS_PER_ROUND = 2 # How many clients to sample per round.\n",
    "TEST_CLIENTS_PER_ROUND = 2 # How many clients to sample per round for test data\n",
    "\n",
    "CLIENT_EPOCHS_PER_ROUND = 3 # Number of epochs in the client to take per round.\n",
    "BATCH_SIZE = 8 # Batch size used on the client.\n",
    "TEST_BATCH_SIZE = 8 # Minibatch size of test data.\n",
    "\n",
    "BUFFER_SIZE = 100 # For dataset shuffling\n",
    "\n",
    "# Maximum length of input token sequence for BERT.\n",
    "BERT_MAX_SEQ_LENGTH = 128\n",
    "\n",
    "# Optimizer configuration\n",
    "SERVER_LEARNING_RATE = 1.0 # Server learning rate.\n",
    "CLIENT_LEARNING_RATE = 0.000001 # Client learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-tHcHX0FQvz"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 65950,
     "status": "ok",
     "timestamp": 1605671693640,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "cVkK1BV9FQv3"
   },
   "outputs": [],
   "source": [
    "train_client_data, test_client_data = tff.simulation.datasets.shakespeare.load_data(cache_dir='./tff_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 67693,
     "status": "ok",
     "timestamp": 1605671695400,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "ZXmJYQbeFQwG"
   },
   "outputs": [],
   "source": [
    "mobilebert_tokenizer = transformers.MobileBertTokenizer.from_pretrained(\n",
    "    'google/mobilebert-uncased', cache_dir='./transformers_cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNYlFQJ3Wt1O"
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 67699,
     "status": "ok",
     "timestamp": 1605671695421,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "8c7S9s9qRlsi"
   },
   "outputs": [],
   "source": [
    "# Imitate transformers tokenizer with TF.Text Tokenizer\n",
    "mobilebert_vocab_lookup_table = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=list(mobilebert_tokenizer.vocab.keys()),\n",
    "        values=tf.constant(list(mobilebert_tokenizer.vocab.values()), dtype=tf.int64)),\n",
    "    default_value=0)\n",
    "\n",
    "mobilebert_special_ids_mask_table = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=tf.constant(mobilebert_tokenizer.all_special_ids, dtype=tf.int32),\n",
    "        values=tf.constant(1, dtype=tf.int32, shape=len(mobilebert_tokenizer.all_special_ids)),\n",
    "        key_dtype=tf.int32, value_dtype=tf.int32),\n",
    "    default_value=tf.constant(0, dtype=tf.int32))\n",
    "\n",
    "mobilebert_tokenizer_tf_text = tf_text.BertTokenizer(\n",
    "    vocab_lookup_table=mobilebert_vocab_lookup_table,\n",
    "    suffix_indicator=\"##\",\n",
    "    max_bytes_per_word=mobilebert_tokenizer.wordpiece_tokenizer.max_input_chars_per_word,\n",
    "    max_chars_per_token=None,\n",
    "    token_out_type=tf.int32,\n",
    "    unknown_token=mobilebert_tokenizer.unk_token,\n",
    "    split_unknown_characters=True,\n",
    "    lower_case=True,\n",
    "    keep_whitespace=False,\n",
    "    normalization_form=None,\n",
    "    preserve_unused_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 77
    },
    "executionInfo": {
     "elapsed": 67692,
     "status": "ok",
     "timestamp": 1605671695436,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "5iwW2jo3TFUt",
    "outputId": "946532bb-78b6-4b66-8f05-c2237955a75a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Text tokenizer output shape: tf.Tensor([1 5 1], shape=(3,), dtype=int32)\n",
      "tf.Tensor([[2023 2003 1037 3231 1012]], shape=(1, 5), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'this is a test.'"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if our new tokenizer works\n",
    "ttt = mobilebert_tokenizer_tf_text.tokenize(\"This is a test.\")\n",
    "print(\"TF Text tokenizer output shape:\", tf.shape(ttt.to_tensor()))\n",
    "print(tf.squeeze(ttt.to_tensor(), axis=-1))\n",
    "mobilebert_tokenizer.decode(tf.squeeze(ttt, axis=-1).to_list()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sfMNvpmFQwW"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 67687,
     "status": "ok",
     "timestamp": 1605671695446,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "oIOw1zG1RfnU"
   },
   "outputs": [],
   "source": [
    "# Based on the answers from\n",
    "# https://stackoverflow.com/questions/42334646/tensorflow-pad-unknown-size-tensor-to-a-specific-size/51936821#51936821\n",
    "def dynamic_padding(inp, min_size, constant_values):\n",
    "\n",
    "    pad_size = min_size - tf.shape(inp)[1]\n",
    "    paddings = [[0,0], [0, pad_size]] # assign here, during graph execution\n",
    "\n",
    "    return tf.cast(tf.pad(inp, paddings, constant_values=constant_values), dtype=tf.int32)\n",
    "\n",
    "# New preprocessing steps based on TF.text tokenizer\n",
    "def tokenize_and_mask(x):\n",
    "    # TF.text tokenizer returns RaggedTensor. Convert this to a regular tensor.\n",
    "    # Note: In the third dimension, 2nd and 3rd indexes contain some sort of offset information,\n",
    "    # which we will ignore for now.\n",
    "    tokenized = mobilebert_tokenizer_tf_text.tokenize(tf.reshape(x['snippets'], shape=[1])).to_tensor()[:, :, 0]\n",
    "\n",
    "    # Add special tokens: [CLS]\n",
    "    cls_tensor_for_tokenized = tf.constant(mobilebert_tokenizer.cls_token_id, shape=[len(x), 1], dtype=tf.int32)\n",
    "    tokenized_with_special_tokens = tf.concat([cls_tensor_for_tokenized, tokenized], axis=1)\n",
    "\n",
    "    # Truncate if the sequence is already longer than BERT_MAX_SEQ_LENGTH\n",
    "    tokenized_with_special_tokens = tf.cond(\n",
    "        tf.greater_equal(tf.shape(tokenized_with_special_tokens)[1], BERT_MAX_SEQ_LENGTH),\n",
    "        true_fn=lambda: tokenized_with_special_tokens[:, 0:BERT_MAX_SEQ_LENGTH-1],\n",
    "        false_fn=lambda: tokenized_with_special_tokens)     \n",
    "\n",
    "    # Add special tokens: [SEP]\n",
    "    sep_tensor_for_tokenized = tf.constant(mobilebert_tokenizer.sep_token_id, shape=[len(x), 1], dtype=tf.int32)\n",
    "    tokenized_with_special_tokens = tf.concat([tokenized_with_special_tokens, sep_tensor_for_tokenized], axis=1)\n",
    "\n",
    "    # Padding with [PAD]\n",
    "    # Final sequence should have the length of BERT_MAX_SEQ_LENGTH\n",
    "    # Pad only if necessary\n",
    "    tokenized_with_special_tokens = tf.cond(\n",
    "        tf.less(tf.shape(tokenized_with_special_tokens)[1], BERT_MAX_SEQ_LENGTH),\n",
    "        true_fn=lambda: dynamic_padding(tokenized_with_special_tokens, BERT_MAX_SEQ_LENGTH, mobilebert_tokenizer.pad_token_id),\n",
    "        false_fn=lambda: tokenized_with_special_tokens)  \n",
    "\n",
    "    tokenized_with_special_tokens = tf.cast(tokenized_with_special_tokens, dtype=tf.int32)\n",
    "\n",
    "    # Random masking for the BERT MLM\n",
    "    masked, labels = utils.get_masked_input_and_labels(\n",
    "        tokenized_with_special_tokens,\n",
    "        mobilebert_vocab_lookup_table,\n",
    "        mobilebert_special_ids_mask_table,\n",
    "        tf.constant(mobilebert_tokenizer.mask_token_id, dtype=tf.int32))\n",
    "\n",
    "    # Squeeze out the first dimension\n",
    "    masked = tf.squeeze(masked)\n",
    "    labels = tf.squeeze(labels)\n",
    "\n",
    "    # Manually settting the shape here so that TensorFlow graph\n",
    "    # could know the sizes in advnace\n",
    "    masked.set_shape(BERT_MAX_SEQ_LENGTH)\n",
    "    labels.set_shape(BERT_MAX_SEQ_LENGTH)\n",
    "    \n",
    "    return masked, labels\n",
    "\n",
    "def preprocess_for_train(train_dataset):\n",
    "    return (\n",
    "        # Filter out empty strings\n",
    "        train_dataset.filter(lambda x: tf.strings.length(x['snippets']) > 0)\n",
    "        # Tokenize each samples using MobileBERT tokenizer\n",
    "        .map(tokenize_and_mask)\n",
    "        # Shuffle\n",
    "        .shuffle(BUFFER_SIZE)\n",
    "        # Repeat to make each client train multiple epochs\n",
    "        .repeat(count=CLIENT_EPOCHS_PER_ROUND)\n",
    "        # Form minibatches\n",
    "        # Use drop_remainder=True to force the batch size to be exactly BATCH_SIZE\n",
    "        # and make the shape **exactly** (BATCH_SIZE, SEQ_LENGTH)\n",
    "        .batch(BATCH_SIZE, drop_remainder=True))\n",
    "    \n",
    "def preprocess_for_test(test_dataset):\n",
    "    return (\n",
    "        # Filter out empty strings\n",
    "        test_dataset.filter(lambda x: tf.strings.length(x['snippets']) > 0)\n",
    "        # Tokenize each samples using MobileBERT tokenizer\n",
    "        .map(tokenize_and_mask)\n",
    "        # Shuffle\n",
    "        .shuffle(BUFFER_SIZE)\n",
    "        # Form minibatches\n",
    "        # Use drop_remainder=True to force the batch size to be exactly TEST_BATCH_SIZE\n",
    "        # and make the shape **exactly** (TEST_BATCH_SIZE, SEQ_LENGTH)\n",
    "        .batch(TEST_BATCH_SIZE, drop_remainder=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69940,
     "status": "ok",
     "timestamp": 1605671697714,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "zMIo2trUC7F7",
    "outputId": "6065703c-476c-49a2-93e5-715fa823a1a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting LookupTableFindV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting LookupTableFindV2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/BERTerated/utils.py:150: Bernoulli.__init__ (from tensorflow.python.ops.distributions.bernoulli) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/BERTerated/utils.py:150: Bernoulli.__init__ (from tensorflow.python.ops.distributions.bernoulli) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/bernoulli.py:97: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/bernoulli.py:97: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting LookupTableFindV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting LookupTableFindV2\n"
     ]
    }
   ],
   "source": [
    "train_client_data = train_client_data.preprocess(preprocess_fn=preprocess_for_train)\n",
    "test_client_data = test_client_data.preprocess(preprocess_fn=preprocess_for_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70506,
     "status": "ok",
     "timestamp": 1605671698297,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "b8NzsgjFFQwp",
    "outputId": "e031e2c9-994e-4945-a602-6aa1636816f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting LookupTableFindV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting LookupTableFindV2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(8, 128), dtype=tf.int32, name=None), TensorSpec(shape=(8, 128), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "# Create a test client dataset, just to get the element_spec info\n",
    "example_dataset = train_client_data.create_tf_dataset_for_client('THE_TRAGEDY_OF_KING_LEAR_KING')\n",
    "print(example_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71009,
     "status": "ok",
     "timestamp": 1605671698814,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "qa-KoFpz1jbt",
    "outputId": "15241876-1417-4f02-e694-5ae4b9fdd77a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  101 14383  1997 ...     0     0     0]\n",
      " [  101 21658  1010 ...     0     0     0]\n",
      " [  101  2065  2017 ...     0     0     0]\n",
      " ...\n",
      " [  101  2588  3067 ...     0     0     0]\n",
      " [  101 10590  1997 ...     0     0     0]\n",
      " [  101  1996  7909 ...  2000  2031   102]], shape=(8, 128), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[-100 -100 -100 ... -100 -100 -100]\n",
      " [-100 -100 -100 ... -100 -100 -100]\n",
      " [-100 -100 -100 ... -100 -100 -100]\n",
      " ...\n",
      " [-100 -100 -100 ... -100 -100 -100]\n",
      " [-100 -100 -100 ... -100 -100 -100]\n",
      " [-100 -100 -100 ... -100 -100 -100]], shape=(8, 128), dtype=int32)\n",
      "[\"[CLS] dom of navarre, my soul's earth [MASK] s god and body's f'ring patron'- [ reads [MASK]'so it is'- [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", '[CLS] madam, your father here dot intimate [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', \"[CLS] if you deny to dance [MASK] let's hold more [MASK]. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", '[CLS] [MASK] we betrayed thus to thy blasted - [MASK]? soft! w away so fast? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', \"[CLS] with a refined traveller of spain, asho in all the world's new fashion planted, that hat a mint of phrases in his brain ; one who the music of his own vain tongue dot ravi [MASK] en harmony ; a manpost [MASK], whom right and [MASK] have chose as umpire of confronted mutiny [MASK] [MASK] child [MASK] [MASK], that arm high [MASK] for interim to our studies shall [MASK] subscribers in high -imeters words, the worth of many a knight from ta [MASK] lost in populated world's debate. how you [MASK], my [MASK], i know not, i ; but i protest i love to hear him lie, [MASK] i [SEP]\", '[CLS] upon mine honour flexible influential. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', \"[CLS] hector of troy ; [MASK] sw, po the great ; the parish curate, alexander ; ari's page, hercules ; the pe, judas mac. [MASK] if these four worth [MASK] their first show thrive, [MASK] four will change habits and present the other five. [MASK] are dec,'tis not so. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", \"[CLS] the payment of a hundred thousand crowns [MASK] being but the [MASK] half of an entire sum di [MASK] my father in his wars. but say that he or we, as neither have, rec'd that sum, pu there remains unpaid a hundred thousand more, in sure of the which, one part of aquitaine is bound to [MASK] [MASK] although not valued to the money [MASK] s [MASK]. if then the king your father will restore but that one half carly [MASK] un, we [MASK] give [MASK] our right in aquitaine spatial and hold fair friendship with his majesty. but that, it seems, he little purpose, for here heginal demand to have [SEP]\"]\n",
      "tf.Tensor(\n",
      "[[ 101 2115 3203 ...    0    0    0]\n",
      " [ 101 2092 1010 ...    0    0    0]\n",
      " [ 101 2963 2033 ...    0    0    0]\n",
      " ...\n",
      " [ 101 1996 2189 ...    0    0    0]\n",
      " [ 101 1998 1010 ...    0    0    0]\n",
      " [ 101 1031 9631 ...    0    0    0]], shape=(8, 128), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[-100 -100 -100 ... -100 -100 -100]\n",
      " [-100 -100 -100 ... -100 -100 -100]\n",
      " [-100 -100 -100 ... -100 -100 -100]\n",
      " ...\n",
      " [-100 1996 -100 ... -100 -100 -100]\n",
      " [-100 -100 -100 ... -100 -100 -100]\n",
      " [-100 -100 -100 ... -100 -100 -100]], shape=(8, 128), dtype=int32)\n",
      "['[CLS] your lady is ignorant what it is. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] well, sit out ; go home, be ; adi. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] hear me, dear lady : i have sworn an oath - [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] wen. well, it was proclaimed [MASK]. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] madam, i will, if [MASK] i may. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] the music plays ; [MASK] some motion to it. but your legs should do it. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', \"[CLS] and, if you prove it, [MASK]'ll repay it back [MASK] [MASK] [MASK] aquitaine. satisfy me so revealed [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", '[CLS] [ reads ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "tf.Tensor(\n",
      "[[ 101 1045 2572 ...    0    0    0]\n",
      " [ 101 2035 5320 ...    0    0    0]\n",
      " [ 101  103 2995 ...    0    0    0]\n",
      " ...\n",
      " [ 101 2256 8295 ...    0    0    0]\n",
      " [ 101 1998 3345 ...    0    0    0]\n",
      " [ 101 2008 2062 ...    0    0    0]], shape=(8, 128), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[-100 -100 2572 ... -100 -100 -100]\n",
      " [-100 -100 -100 ... -100 -100 -100]\n",
      " [-100 1037 -100 ... -100 -100 -100]\n",
      " ...\n",
      " [-100 -100 -100 ... -100 -100 -100]\n",
      " [-100 -100 -100 ... -100 -100 -100]\n",
      " [-100 -100 -100 ... -100 -100 -100]], shape=(8, 128), dtype=int32)\n",
      "[\"[CLS] i am best pleas'd with that. [ they [MASK] [MASK] [MASK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", \"[CLS] all causes to the [MASK] of [MASK] catalonia ; and often at his [MASK] loose [MASK] that which long process could not ar. and though the mourning [MASK] of [MASK] forbid the smiling courtesy of love the holy suit which fai it would convince, yet, since love [MASK] s [MASK] was first on foot, papal not the cloud of sorrow just it from what it pu'd ; [MASK] to wai [MASK] [MASK] [MASK] not by much so whole - profitable [MASK] to re at friends but newly [MASK]. now, at the latest minute of the hour, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", '[CLS] [MASK] true man or a thief that gallo so? what present has thou there? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] these be the stops [MASK] hind study quite, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] more measure [MASK] this measure ; be not nice [MASK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] our loving lawful [MASK] and our faith not torn. saint cup, then! and [MASK] soldiers, to the field! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', \"[CLS] and train our intellect to vain delight [MASK] how well [MASK]'s commenced, to [MASK] against reading! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", '[CLS] that more than all the world i did respect her る [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n"
     ]
    }
   ],
   "source": [
    "# Did the random masking go well?\n",
    "for example_input, example_labels in example_dataset.take(3):\n",
    "    print(example_input)\n",
    "    print(example_labels)\n",
    "\n",
    "    print(mobilebert_tokenizer.batch_decode(tf.squeeze(example_input).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_o5NZpuzFQw7"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 78844,
     "status": "ok",
     "timestamp": 1605671706663,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "kfTDbXNpnr1A",
    "outputId": "82dbc632-0d88-40cc-bdec-744030dc712b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/mobilebert-uncased were not used when initializing TFMobileBertModel: ['predictions___cls', 'seq_relationship___cls']\n",
      "- This IS expected if you are initializing TFMobileBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFMobileBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFMobileBertModel were initialized from the model checkpoint at google/mobilebert-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMobileBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "mobilebert_model = transformers.TFMobileBertModel.from_pretrained(\n",
    "    'google/mobilebert-uncased', cache_dir='./transformers_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 83862,
     "status": "ok",
     "timestamp": 1605671711695,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "FDOF1EcWrOVJ"
   },
   "outputs": [],
   "source": [
    "# Due to the limitations with Keras subclasses, we can only use the main layer part from pretrained models\n",
    "# and add output heads by ourselves\n",
    "mobilebert_keras_converted = utils.convert_huggingface_mlm_to_keras(\n",
    "    huggingface_model=mobilebert_model,\n",
    "    max_seq_length=BERT_MAX_SEQ_LENGTH,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 83850,
     "status": "ok",
     "timestamp": 1605671711702,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "tblHhwjqEqfw"
   },
   "outputs": [],
   "source": [
    "# Use lists of NumPy arrays to backup pretained weights\n",
    "mobilebert_pretrained_trainable_weights = []\n",
    "mobilebert_pretrained_non_trainable_weights = []\n",
    "\n",
    "for w in mobilebert_keras_converted.trainable_weights:\n",
    "    mobilebert_pretrained_trainable_weights.append(w.numpy())\n",
    "\n",
    "for w in mobilebert_keras_converted.non_trainable_weights:\n",
    "    mobilebert_pretrained_non_trainable_weights.append(w.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 83844,
     "status": "ok",
     "timestamp": 1605671711706,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "2kRecwJPFQw-"
   },
   "outputs": [],
   "source": [
    "def tff_model_fn():\n",
    "    \"\"\"Constructs a fully initialized model for use in federated averaging.\"\"\"\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model_wrapped = utils.KerasModelWrapper(\n",
    "        tf.keras.models.clone_model(mobilebert_keras_converted), example_dataset.element_spec, loss)\n",
    "\n",
    "    return model_wrapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qM6T_Mp8FQxQ"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXwPdo-_Qrsk"
   },
   "source": [
    "### Training setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 84568,
     "status": "ok",
     "timestamp": 1605671712441,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "vPNLTNLWQwDX"
   },
   "outputs": [],
   "source": [
    "def server_optimizer_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=SERVER_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 84562,
     "status": "ok",
     "timestamp": 1605671712446,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "JEPK0AlzujvZ"
   },
   "outputs": [],
   "source": [
    "def client_optimizer_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=CLIENT_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194105,
     "status": "ok",
     "timestamp": 1605671822000,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "qBzCiCkWFQxW",
    "outputId": "0e6b4179-2286-4266-9a4f-853ac7b5a31c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/operators/control_flow.py:565: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/operators/control_flow.py:565: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
     ]
    }
   ],
   "source": [
    "iterative_process = fedavg.build_federated_averaging_process(\n",
    "    model_fn=tff_model_fn,\n",
    "    model_input_spec=example_dataset.element_spec,\n",
    "    initial_trainable_weights=mobilebert_pretrained_trainable_weights,\n",
    "    initial_non_trainable_weights=mobilebert_pretrained_non_trainable_weights,\n",
    "    server_optimizer_fn=server_optimizer_fn, \n",
    "    client_optimizer_fn=client_optimizer_fn)\n",
    "\n",
    "server_state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 199308,
     "status": "ok",
     "timestamp": 1605671827218,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "qWGC89ZVWt1c"
   },
   "outputs": [],
   "source": [
    "model_final = tff_model_fn()\n",
    "metric_test = tf.keras.metrics.SparseCategoricalCrossentropy(from_logits=True, name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oqCXFc7gFQxl",
    "outputId": "778e5e65-de93-4b59-99de-a9b43912e735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosing clients to use for training...\n",
      "WARNING:tensorflow:Using a while_loop for converting LookupTableFindV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting LookupTableFindV2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting LookupTableFindV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting LookupTableFindV2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training clients selection complete.\n",
      "Round 0 start!\n",
      "Client 9650 : updated the model with server message.\n",
      "Client 9650 : training start.\n",
      "Client 21408 : updated the model with server message.\n",
      "Client 21408 : training start.\n",
      "Client 9650 : 8 processed\n",
      "Client 21408 : 8 processed\n",
      "Client 9650 : 16 processed\n",
      "Client 21408 : 16 processed\n",
      "Client 21408 : 24 processed\n",
      "Client 21408 : 32 processed\n",
      "Client 21408 : 40 processed\n",
      "Client 21408 : 48 processed\n",
      "Client 21408 : 56 processed\n",
      "Client 21408 : 64 processed\n",
      "Client 21408 : 72 processed\n",
      "Client 21408 : 80 processed\n",
      "Client 21408 : 88 processed\n",
      "Client 21408 : 96 processed\n",
      "Client 21408 : 104 processed\n",
      "Client 21408 : 112 processed\n",
      "Client 21408 : 120 processed\n"
     ]
    }
   ],
   "source": [
    "for round_num in range(TOTAL_ROUNDS):\n",
    "\n",
    "    # Training clients selection\n",
    "    print(\"Choosing clients to use for training...\")\n",
    "\n",
    "    sampled_clients = np.random.choice(\n",
    "        train_client_data.client_ids,\n",
    "        size=TRAIN_CLIENTS_PER_ROUND,\n",
    "        replace=False)\n",
    "\n",
    "    sampled_train_data = [\n",
    "        train_client_data.create_tf_dataset_for_client(client)\n",
    "        for client in sampled_clients\n",
    "    ]\n",
    "\n",
    "    print(\"Training clients selection complete.\")\n",
    "\n",
    "    # FedAvg\n",
    "    print(f'Round {round_num} start!')\n",
    "\n",
    "    server_state, train_metrics = iterative_process.next(server_state, sampled_train_data)\n",
    "\n",
    "    print(f'Round {round_num} training loss: {train_metrics}')\n",
    "\n",
    "    # Evaluation\n",
    "    if round_num % ROUNDS_PER_EVAL == 0:\n",
    "        model_final.from_weights(server_state.model_weights)\n",
    "\n",
    "        # Test dataset generation for this round\n",
    "        print(\"Sampling clients to use for testing...\")\n",
    "\n",
    "        sampled_test_clients = np.random.choice(\n",
    "            test_client_data.client_ids,\n",
    "            size=TEST_CLIENTS_PER_ROUND,\n",
    "            replace=False)\n",
    "\n",
    "        sampled_test_data = [\n",
    "            test_client_data.create_tf_dataset_for_client(client)\n",
    "            for client in sampled_test_clients\n",
    "        ]\n",
    "\n",
    "        sampled_test_data_merged = sampled_test_data[0]\n",
    "\n",
    "        if len(sampled_test_data) > 1:\n",
    "            for client_test in range(1, len(sampled_test_data)):\n",
    "                sampled_test_data_merged.concatenate(sampled_test_data[1])\n",
    "\n",
    "        print(\"Test clients selected.\")\n",
    "\n",
    "        metric_validation = utils.keras_evaluate(model_final.keras_model, sampled_test_data_merged, metric_test)\n",
    "\n",
    "        print(f'Round {round_num} validation metric: {metric_validation}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mobilebert_mlm_shakespeare_fedavg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
