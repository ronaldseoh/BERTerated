{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6qruq9ZFQsN"
   },
   "source": [
    "# Further Pre-training MobileBERT MLM with Federated Averaging (Shakepeare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 975,
     "status": "ok",
     "timestamp": 1605944927157,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "-AgOn_qCFQsk"
   },
   "outputs": [],
   "source": [
    "# Copyright 2020, The TensorFlow Federated Authors.\n",
    "# Copyright 2020, Ronald Seoh\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zUGmvEbFQts"
   },
   "source": [
    "## Google Colab settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46165,
     "status": "ok",
     "timestamp": 1605944972371,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "_1nBG9qaFQt9",
    "outputId": "c9f488ea-6010-4220-d000-5cf2efda5a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/Colab Notebooks/BERTerated\n",
      "datasets\t\t\t\t      __pycache__\n",
      "fedavg_client.py\t\t\t      README.md\n",
      "fedavg.py\t\t\t\t      requirements.txt\n",
      "huggingface_keras_layers.py\t\t      tff_cache\n",
      "LICENSE\t\t\t\t\t      trained_models\n",
      "mobilebert_mlm_shakespeare_centralized.ipynb  transformers_cache\n",
      "mobilebert_mlm_shakespeare_fedavg.ipynb       utils.py\n",
      "mobilebert_mlm_stackoverflow_fedavg.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Use Google Colab\n",
    "use_colab = True\n",
    "\n",
    "# Is this notebook running on Colab?\n",
    "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
    "# should be available in this environment\n",
    "\n",
    "# Previous version used importlib, but we could do the same thing with\n",
    "# just attempting to import google.colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab_available = True\n",
    "except:\n",
    "    colab_available = False\n",
    "\n",
    "if use_colab and colab_available:\n",
    "    # Mount Google Drive root directory\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # cd to the appropriate working directory under my Google Drive\n",
    "    %cd '/content/drive/My Drive/Colab Notebooks/BERTerated'\n",
    "    \n",
    "    # List the directory contents\n",
    "    !ls\n",
    "\n",
    "# IPython reloading magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67101,
     "status": "ok",
     "timestamp": 1605944993327,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "D_PBfwhLUQ03",
    "outputId": "729500b2-ab17-4732-eaed-ca339d9331db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-federated==0.17.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/54/900d99d3cff21b6a570281b51f4878a745c0eece7732bb7fc26eee61ef57/tensorflow_federated-0.17.0-py2.py3-none-any.whl (517kB)\n",
      "\u001b[K     |████████████████████████████████| 522kB 8.6MB/s \n",
      "\u001b[?25hCollecting tensorflow-text==2.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/b2/2dbd90b93913afd07e6101b8b84327c401c394e60141c1e98590038060b3/tensorflow_text-2.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.6MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6MB 9.9MB/s \n",
      "\u001b[?25hCollecting transformers==3.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 57.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow~=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (2.3.0)\n",
      "Collecting attrs~=19.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/db/4313ab3be961f7a763066401fb77f7748373b6094076ae2bda2806988af6/attrs-19.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy~=1.18.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.18.5)\n",
      "Collecting tensorflow-addons~=0.11.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/f8/d6fca180c123f2851035c4493690662ebdad0849a9059d56035434bff5c9/tensorflow_addons-0.11.2-cp36-cp36m-manylinux2010_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 42.9MB/s \n",
      "\u001b[?25hCollecting cachetools~=3.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (2.10.0)\n",
      "Collecting tensorflow-privacy~=0.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/ae/7db0dcf76a746314a174578a7b99ff098b40b908c4c693a955a2bbc0127b/tensorflow_privacy-0.5.1-py3-none-any.whl (149kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 42.9MB/s \n",
      "\u001b[?25hCollecting semantic-version~=2.8.5\n",
      "  Downloading https://files.pythonhosted.org/packages/a5/15/00ef3b7888a10363b7c402350eda3acf395ff05bebae312d1296e528516a/semantic_version-2.8.5-py2.py3-none-any.whl\n",
      "Collecting absl-py~=0.9.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 50.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: portpicker~=1.3.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: retrying~=1.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.3.3)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (0.1.5)\n",
      "Collecting tensorflow-model-optimization~=0.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/cc/4b0831f492396f03a4563cc749ad94cbf7af986aaa7a7d89e5979029ce5c/tensorflow_model_optimization-0.4.1-py2.py3-none-any.whl (172kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 50.3MB/s \n",
      "\u001b[?25hCollecting grpcio~=1.29.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/04/2b67f0a3645481235d5547891fd0e45e384f1ae5676788f24a7c8735b4e9/grpcio-1.29.0-cp36-cp36m-manylinux2010_x86_64.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 52.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0->-r requirements.txt (line 3)) (2.23.0)\n",
      "Collecting tokenizers==0.9.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 50.0MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 48.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0->-r requirements.txt (line 3)) (2019.12.20)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 50.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0->-r requirements.txt (line 3)) (3.12.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0->-r requirements.txt (line 3)) (4.41.1)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0->-r requirements.txt (line 3)) (0.7)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0->-r requirements.txt (line 3)) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0->-r requirements.txt (line 3)) (20.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (0.35.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.12.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.1.2)\n",
      "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (0.3.3)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (3.3.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons~=0.11.1->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (2.7.1)\n",
      "Requirement already satisfied: mpmath in /usr/local/lib/python3.6/dist-packages (from tensorflow-privacy~=0.5.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 3)) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 3)) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 3)) (2020.6.20)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0->-r requirements.txt (line 3)) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0->-r requirements.txt (line 3)) (0.17.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.4.0->-r requirements.txt (line 3)) (50.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.4.0->-r requirements.txt (line 3)) (2.4.7)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (3.3.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (0.4.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.17.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (0.4.8)\n",
      "Building wheels for collected packages: absl-py, sacremoses\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for absl-py: filename=absl_py-0.9.0-cp36-none-any.whl size=121933 sha256=4c77150aec9ea5ce4a4e966a784bb2aed14f5679d4597fded2a5c0374a94cb0b\n",
      "  Stored in directory: /root/.cache/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=c0058f79981bfee1935237ab2b797d28b97068972fcd200482399962e6a1fe13\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built absl-py sacremoses\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: attrs, tensorflow-addons, cachetools, tensorflow-privacy, semantic-version, absl-py, tensorflow-model-optimization, grpcio, tensorflow-federated, tensorflow-text, tokenizers, sacremoses, sentencepiece, transformers\n",
      "  Found existing installation: attrs 20.2.0\n",
      "    Uninstalling attrs-20.2.0:\n",
      "      Successfully uninstalled attrs-20.2.0\n",
      "  Found existing installation: tensorflow-addons 0.8.3\n",
      "    Uninstalling tensorflow-addons-0.8.3:\n",
      "      Successfully uninstalled tensorflow-addons-0.8.3\n",
      "  Found existing installation: cachetools 4.1.1\n",
      "    Uninstalling cachetools-4.1.1:\n",
      "      Successfully uninstalled cachetools-4.1.1\n",
      "  Found existing installation: tensorflow-privacy 0.2.2\n",
      "    Uninstalling tensorflow-privacy-0.2.2:\n",
      "      Successfully uninstalled tensorflow-privacy-0.2.2\n",
      "  Found existing installation: absl-py 0.10.0\n",
      "    Uninstalling absl-py-0.10.0:\n",
      "      Successfully uninstalled absl-py-0.10.0\n",
      "  Found existing installation: grpcio 1.33.2\n",
      "    Uninstalling grpcio-1.33.2:\n",
      "      Successfully uninstalled grpcio-1.33.2\n",
      "Successfully installed absl-py-0.9.0 attrs-19.3.0 cachetools-3.1.1 grpcio-1.29.0 sacremoses-0.0.43 semantic-version-2.8.5 sentencepiece-0.1.94 tensorflow-addons-0.11.2 tensorflow-federated-0.17.0 tensorflow-model-optimization-0.4.1 tensorflow-privacy-0.5.1 tensorflow-text-2.3.0 tokenizers-0.9.2 transformers-3.4.0\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F16eB2w-FQuw"
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81445,
     "status": "ok",
     "timestamp": 1605945007690,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "k_SnruV2FQu0",
    "outputId": "467d13bd-c39d-4b22-ffa3-a0fa4626aaf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'Hello, World!'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import tensorflow_text as tf_text\n",
    "import transformers\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import fedavg\n",
    "import fedavg_client\n",
    "import datasets\n",
    "import utils\n",
    "\n",
    "# Random seed settings\n",
    "random_seed = 692\n",
    "random.seed(random_seed) # Python\n",
    "np.random.seed(random_seed) # NumPy\n",
    "tf.random.set_seed(random_seed) # TensorFlow\n",
    "\n",
    "# Tensorflow GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Test the TFF is working:\n",
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81441,
     "status": "ok",
     "timestamp": 1605945007703,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "FHYxELiQFQvI",
    "outputId": "0a58d004-fc11-4b4d-e907-abb9a4ef0a18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.9 (default, Oct  8 2020, 12:12:24) \n",
      "[GCC 8.4.0]\n",
      "NumPy version: 1.18.5\n",
      "TensorFlow version: 2.3.0\n",
      "TensorFlow Federated version: 0.17.0\n",
      "Transformers version: 3.4.0\n"
     ]
    }
   ],
   "source": [
    "# Print version information\n",
    "print(\"Python version: \" + sys.version)\n",
    "print(\"NumPy version: \" + np.__version__)\n",
    "print(\"TensorFlow version: \" + tf.__version__)\n",
    "print(\"TensorFlow Federated version: \" + tff.__version__)\n",
    "print(\"Transformers version: \" + transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81730,
     "status": "ok",
     "timestamp": 1605945008009,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "KGCWO7YprvKD",
    "outputId": "d7142c32-e577-4563-f54c-533c3552b396"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 21 07:50:07 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   54C    P0    29W /  70W |    229MiB / 15079MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYXMEboAFQvd"
   },
   "source": [
    "## Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 81718,
     "status": "ok",
     "timestamp": 1605945008013,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "M071lqOQFQvi"
   },
   "outputs": [],
   "source": [
    "TOTAL_ROUNDS = 6 # Number of total training rounds\n",
    "ROUNDS_PER_EVAL = 3 # How often to evaluate\n",
    "\n",
    "TRAIN_CLIENTS_PER_ROUND = 3 # How many clients to sample per round.\n",
    "TEST_CLIENTS_PER_ROUND = 3 # How many clients to sample per round for test data\n",
    "\n",
    "CLIENT_EPOCHS_PER_ROUND = 3 # Number of epochs in the client to take per round.\n",
    "\n",
    "BATCH_SIZE = 8 # Batch size used on the client.\n",
    "TEST_BATCH_SIZE = 8 # Minibatch size of test data.\n",
    "\n",
    "# Maximum length of input token sequence for BERT.\n",
    "BERT_MAX_SEQ_LENGTH = 64\n",
    "\n",
    "# Optimizer configuration\n",
    "SERVER_LEARNING_RATE = 1.0 # Server learning rate.\n",
    "CLIENT_LEARNING_RATE = 2e-5 # Client learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-tHcHX0FQvz"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 84054,
     "status": "ok",
     "timestamp": 1605945010359,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "cVkK1BV9FQv3"
   },
   "outputs": [],
   "source": [
    "train_client_data, test_client_data = tff.simulation.datasets.shakespeare.load_data(cache_dir='./tff_cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNYlFQJ3Wt1O"
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 86032,
     "status": "ok",
     "timestamp": 1605945012347,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "ZXmJYQbeFQwG"
   },
   "outputs": [],
   "source": [
    "mobilebert_tokenizer = transformers.MobileBertTokenizer.from_pretrained(\n",
    "    'google/mobilebert-uncased', cache_dir='./transformers_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 86032,
     "status": "ok",
     "timestamp": 1605945012355,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "8c7S9s9qRlsi"
   },
   "outputs": [],
   "source": [
    "# Imitate transformers tokenizer with TF.Text Tokenizer\n",
    "tokenizer_tf_text, vocab_lookup_table, special_ids_mask_table = datasets.preprocessing_for_bert.convert_huggingface_tokenizer(mobilebert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 77
    },
    "executionInfo": {
     "elapsed": 86028,
     "status": "ok",
     "timestamp": 1605945012366,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "5iwW2jo3TFUt",
    "outputId": "5ea97864-1eb5-4b69-df1a-a22d49090549"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Text tokenizer output shape: tf.Tensor([1 5 1], shape=(3,), dtype=int32)\n",
      "tf.Tensor([[2023 2003 1037 3231 1012]], shape=(1, 5), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'this is a test.'"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if our new tokenizer works\n",
    "ttt = tokenizer_tf_text.tokenize(\"This is a test.\")\n",
    "print(\"TF Text tokenizer output shape:\", tf.shape(ttt.to_tensor()))\n",
    "print(tf.squeeze(ttt.to_tensor(), axis=-1))\n",
    "mobilebert_tokenizer.decode(tf.squeeze(ttt, axis=-1).to_list()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sfMNvpmFQwW"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 86342,
     "status": "ok",
     "timestamp": 1605945012694,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "oIOw1zG1RfnU"
   },
   "outputs": [],
   "source": [
    "def check_empty_snippet(x):\n",
    "    return tf.strings.length(x['snippets']) > 0\n",
    "\n",
    "def tokenizer_and_mask_wrapped(x):\n",
    "\n",
    "    masked, labels = datasets.preprocessing_for_bert.tokenize_and_mask(tf.reshape(x['snippets'], shape=[1]),\n",
    "                                                                       max_seq_length=BERT_MAX_SEQ_LENGTH,\n",
    "                                                                       bert_tokenizer_tf_text=tokenizer_tf_text,\n",
    "                                                                       vocab_lookup_table=vocab_lookup_table,\n",
    "                                                                       special_ids_mask_table=special_ids_mask_table,\n",
    "                                                                       cls_token_id=mobilebert_tokenizer.cls_token_id,\n",
    "                                                                       sep_token_id=mobilebert_tokenizer.sep_token_id,\n",
    "                                                                       pad_token_id=mobilebert_tokenizer.pad_token_id,\n",
    "                                                                       mask_token_id=mobilebert_tokenizer.mask_token_id)\n",
    "\n",
    "    return (masked, labels)\n",
    "\n",
    "def preprocess_for_train(train_dataset):\n",
    "    return (\n",
    "        train_dataset\n",
    "        # Tokenize each samples using MobileBERT tokenizer\n",
    "        .map(tokenizer_and_mask_wrapped, num_parallel_calls=tf.data.experimental.AUTOTUNE, deterministic=False)\n",
    "        # Shuffle\n",
    "        .shuffle(100000)\n",
    "        # Form minibatches\n",
    "        # Use drop_remainder=True to force the batch size to be exactly BATCH_SIZE\n",
    "        # and make the shape **exactly** (BATCH_SIZE, SEQ_LENGTH)\n",
    "        .batch(BATCH_SIZE, drop_remainder=True)\n",
    "        # Repeat to make each client train multiple epochs\n",
    "        .repeat(count=CLIENT_EPOCHS_PER_ROUND)\n",
    "    )\n",
    "    \n",
    "def preprocess_for_test(test_dataset):\n",
    "    return (\n",
    "        test_dataset\n",
    "        # Tokenize each samples using MobileBERT tokenizer\n",
    "        .map(tokenizer_and_mask_wrapped, num_parallel_calls=tf.data.experimental.AUTOTUNE, deterministic=False)\n",
    "        # Shuffle\n",
    "        .shuffle(100000)\n",
    "        # Form minibatches\n",
    "        # Use drop_remainder=True to force the batch size to be exactly TEST_BATCH_SIZE\n",
    "        # and make the shape **exactly** (TEST_BATCH_SIZE, SEQ_LENGTH)\n",
    "        .batch(TEST_BATCH_SIZE, drop_remainder=True)\n",
    "    )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 86336,
     "status": "ok",
     "timestamp": 1605945012697,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "kJHkMtw9oTZ4"
   },
   "outputs": [],
   "source": [
    "train_client_data = train_client_data.preprocess(preprocess_fn=lambda x: x.filter(check_empty_snippet))\n",
    "test_client_data = test_client_data.preprocess(preprocess_fn=lambda x: x.filter(check_empty_snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 89170,
     "status": "ok",
     "timestamp": 1605945015541,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "zMIo2trUC7F7",
    "outputId": "5345735d-b84c-4073-e0db-00bde6be4956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/BERTerated/datasets/preprocessing_for_bert.py:76: Bernoulli.__init__ (from tensorflow.python.ops.distributions.bernoulli) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/BERTerated/datasets/preprocessing_for_bert.py:76: Bernoulli.__init__ (from tensorflow.python.ops.distributions.bernoulli) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/bernoulli.py:97: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/bernoulli.py:97: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "train_client_data = train_client_data.preprocess(preprocess_fn=preprocess_for_train)\n",
    "test_client_data = test_client_data.preprocess(preprocess_fn=preprocess_for_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 89161,
     "status": "ok",
     "timestamp": 1605945015546,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "b8NzsgjFFQwp",
    "outputId": "80ce0c64-a0ce-49df-f108-405de5656a69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(8, 64), dtype=tf.int32, name=None), TensorSpec(shape=(8, 64), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "# Create an example client dataset, just to get the element_spec info\n",
    "example_dataset = train_client_data.create_tf_dataset_for_client('THE_TRAGEDY_OF_KING_LEAR_KING')\n",
    "print(example_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 89835,
     "status": "ok",
     "timestamp": 1605945016236,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "qa-KoFpz1jbt",
    "outputId": "6bb3d5ee-5343-483d-d3f4-aae1cddee55c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  101  2070  4024  2005  2068  1999  2037 17732  1012  2185  1010  2185\n",
      "    999  2053  2051   103  2022 16647   102     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  2054  2360  2017  1010  8140  1029  2339  1010  2023  2001  3243\n",
      "    103   103   102     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  2065  2017  9772  2000  3153  1010  2292   103  1055  2907  2062\n",
      "    103   103   102     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  2024  2057 12056  2947  2000 15177 19934  1011  3193  1029  3730\n",
      "    103  1059   103  2061  3435  1029   102     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  2007  1037 15514 21916  1997   103  1010  1037  2158  1999  2035\n",
      "   1996  2088  1005   103  2047  4827   103  1010  2008  6045  1037 12927\n",
      "   1997 15672  1999  2010  4167  1025  2028  2040  1996   103  1997  2010\n",
      "    103   103  4416 11089 16806  2066  4372  9396  1025  1037  2158  1997\n",
      "  13711  1010  3183  2157  1998  3308  2031  4900  2004 20887  1997   103\n",
      "  19306  1012  2023   102]\n",
      " [  101  1996  7909 16151  1037  3634  4595   103  1025  2108  2021  1996\n",
      "   2028  2431  1997  2019  2972  7680  4487  2011  2026  2269  1999  2010\n",
      "   5233  1012  2021   103  2008  2002  2030  2057  1010  2004  4445   103\n",
      "   1010 28565  1005  1040  2008  7680   103  2664   103  3464 23850  1037\n",
      "   3634  4595  2062  1010  1999  2469  1997  1996  2029  1010  2028 14872\n",
      "   1997 24973  2003   102]\n",
      " [  101  2059  2681  2023 11834  1025  1998   103  2204  2022  1010  2085\n",
      "   6011   102     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  2588  3067  6225  1010  2053   103   102     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]], shape=(8, 64), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  4618  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  2360  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   9471  1012  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  -100  -100  -100  -100  -100  -100  1005  -100  -100  -100\n",
      "  11834  1012  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  -100  -100  -100  -100  -100  2058  -100  -100  -100  -100\n",
      "    999  -100  2185  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  -100  -100  -100  -100  3577  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  1055  -100  -100  8461  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  2189  -100  -100\n",
      "   2219 15784  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  4900  -100  -100  -100  2037\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  -100  1997  -100  -100  -100 24364  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  2360  -100  -100  -100  2057  -100  -100  -100  2031\n",
      "   -100 28667  -100  -100  -100  -100  1010  -100  2045  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  2112\n",
      "   -100  -100  2003  -100]\n",
      " [ -100  -100  -100  -100  -100  -100  -100  1010  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  -100  -100  -100  -100  1012  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]], shape=(8, 64), dtype=int32)\n",
      "['[CLS] some entertainment for them in their tents. away, away! no time [MASK] be omitted [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] what say you, lords? why, this was quite [MASK] [MASK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] if you deny to dance, let [MASK] s hold more [MASK] [MASK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] are we betrayed thus to thy wavelength - view? soft [MASK] w [MASK] so fast? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', \"[CLS] with a refined traveller of [MASK], a man in all the world'[MASK] new fashion [MASK], that hat a mint of phrases in his brain ; one who the [MASK] of his [MASK] [MASK] tongue dot ravi like en harmony ; a man of complement, whom right and wrong have chose as umpire of [MASK] mutiny. this [SEP]\", \"[CLS] the payment adopting a hundred thousand [MASK] ; being but the one half of an entire sum di by my father in his wars. but [MASK] that he or we, as neither [MASK], horst'd that sum [MASK] yet [MASK] remains unpaid a hundred thousand more, in sure of the which, one exceeded of aquitaine is [SEP]\", '[CLS] then leave this chat ; and [MASK] good be, now prove [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] upon mine honour, no [MASK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "tf.Tensor(\n",
      "[[  101  2963  2033  1010  6203  3203  1024  1045   103 10741  2019 11292\n",
      "   1011   102     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  2092  1010  4133  2041  1025  2175  2188  1010  2022  1025 27133\n",
      "   1012   102     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  2115  3203  2003   103  2054  2009  2003  1012   102     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101   103  1012   103  1010  2009  2001 10116   103  1012   102     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101 21658  1010  1045   103  1010  2065  3402  1045  2089  1012   102\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101   103  2189  3248  1025 29536  2070  4367  2000  2009  1012  2021\n",
      "   2115  3456  2323  2079   103  1012   102     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101   103  1010   103  2017  6011   103  1010  1045  1005  2222   103\n",
      "   2009  2067  2030 10750  2039 24973  1012 13225  2033  2061  1012   102\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  1031  9631   103   102     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]], shape=(8, 64), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ -100  -100  -100  -100  -100  -100  -100  -100  2031  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  -100  -100 21591  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100 19181  -100  2092  -100  -100  -100  -100 17278  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  -100  -100  2097  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  1996  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  2009  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  1998  -100  2065  -100  -100  2009  -100  -100  -100  -100 24565\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  -100  1033  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]], shape=(8, 64), dtype=int32)\n",
      "['[CLS] hear me, dear lady : i [MASK] sworn an oath - [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] well, sit out ; go home, be ; adi. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] your lady is [MASK] what it is. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] [MASK]. [MASK], it was proclaimed [MASK]. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] madam, i [MASK], if suddenly i may. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] [MASK] music plays ; vo some motion to it. but your legs should do [MASK]. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', \"[CLS] [MASK], [MASK] you prove [MASK], i'll [MASK] it back or yield up aquitaine. satisfy me so. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", '[CLS] [ reads [MASK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "tf.Tensor(\n",
      "[[  101  1045  2572  2190 22512  1005  1040  2007  2008  1012   103   103\n",
      "  23705  4237  1033   102     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  1005 19616  1998 13440  1010   103  2000 15177  2511 10116   102\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  1037  2995  2158  2030  1037 12383  2008 25624  2061   103  2054\n",
      "   2556   103 15223  2045   103   102     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  2122  2022  1996  6762  2008 17666  2817  3243  1010   102     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101   103  5468  1997  2023  5468   103  2022  2025  3835  1012   102\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  2256  8295   103  1010  1998  2256  4752  2025  7950  1012  3002\n",
      "   2452   103  2059   999  1998  1010  3548  1010  2000  1996  2492   103\n",
      "    102     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101   103  3345  2256 24823  2000 15784   103  1012   103  2092  2002\n",
      "   1005  1055  3191  1010  2000  3114  2114  3752   103   102     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101   103   103  2084   103  1996  2088  1045  2106  4847  2014  1012\n",
      "    102     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]], shape=(8, 64), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  1031  2027\n",
      "   -100  4237  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  -100  -100  -100  -100 10043  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  -100  -100  -100  -100 12383  -100  -100  -100  1029  -100\n",
      "   -100  2038  -100  -100  1029  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  2062  -100  -100  -100  5468  1025  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  -100 26410  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  1010  -100  -100  -100  -100  -100  1010  -100  -100  -100   999\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  1998  -100  -100  -100  -100  -100 12208  -100  2129  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100   999  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  2008  2062  -100  2035  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]], shape=(8, 64), dtype=int32)\n",
      "[\"[CLS] i am best pleas'd with that. [MASK] [MASK] converse apart ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", \"[CLS]'sorted and consort, [MASK] to thy established proclaimed [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", '[CLS] a true man or a thief that gallo so [MASK] what present [MASK] thou there [MASK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] these be the stops that hind study quite, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] [MASK] measure of this measure [MASK] be not nice. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] our loving [MASK], and our faith not torn. saint cup [MASK] then! and, soldiers, to the field [MASK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', \"[CLS] [MASK] train our intellect to vain [MASK]. [MASK] well he's read, to reason against reading [MASK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", '[CLS] [MASK] [MASK] than [MASK] the world i did respect her. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n"
     ]
    }
   ],
   "source": [
    "# Did the random masking go well?\n",
    "for example_input, example_labels in example_dataset.take(3):\n",
    "    print(example_input)\n",
    "    print(example_labels)\n",
    "\n",
    "    print(mobilebert_tokenizer.batch_decode(tf.squeeze(example_input).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_o5NZpuzFQw7"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 98652,
     "status": "ok",
     "timestamp": 1605945025068,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "kfTDbXNpnr1A",
    "outputId": "e64a04d9-3664-4292-e141-60037503f610"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFMobileBertForPreTraining.\n",
      "\n",
      "All the layers of TFMobileBertForPreTraining were initialized from the model checkpoint at google/mobilebert-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMobileBertForPreTraining for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "mobilebert_model = transformers.TFMobileBertForPreTraining.from_pretrained(\n",
    "    'google/mobilebert-uncased', cache_dir='./transformers_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 106893,
     "status": "ok",
     "timestamp": 1605945033324,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "FDOF1EcWrOVJ"
   },
   "outputs": [],
   "source": [
    "# Due to the limitations with Keras subclasses, we can only use the main layer part from pretrained models\n",
    "# and add output heads by ourselves\n",
    "mobilebert_keras_converted = utils.convert_huggingface_mlm_to_keras(\n",
    "    huggingface_model=mobilebert_model,\n",
    "    max_seq_length=BERT_MAX_SEQ_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 107205,
     "status": "ok",
     "timestamp": 1605945033644,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "tblHhwjqEqfw"
   },
   "outputs": [],
   "source": [
    "# Use lists of NumPy arrays to backup pretained weights\n",
    "mobilebert_pretrained_trainable_weights = []\n",
    "mobilebert_pretrained_non_trainable_weights = []\n",
    "\n",
    "for w in mobilebert_keras_converted.trainable_weights:\n",
    "    mobilebert_pretrained_trainable_weights.append(w.numpy())\n",
    "\n",
    "for w in mobilebert_keras_converted.non_trainable_weights:\n",
    "    mobilebert_pretrained_non_trainable_weights.append(w.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 107200,
     "status": "ok",
     "timestamp": 1605945033649,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "2kRecwJPFQw-"
   },
   "outputs": [],
   "source": [
    "def tff_model_fn():\n",
    "    \"\"\"Constructs a fully initialized model for use in federated averaging.\"\"\"\n",
    "\n",
    "    loss = utils.MaskedLMCrossEntropy()\n",
    "\n",
    "    model_wrapped = utils.KerasModelWrapper(\n",
    "        tf.keras.models.clone_model(mobilebert_keras_converted),\n",
    "        example_dataset.element_spec, loss)\n",
    "\n",
    "    return model_wrapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qM6T_Mp8FQxQ"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXwPdo-_Qrsk"
   },
   "source": [
    "### Training setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 107193,
     "status": "ok",
     "timestamp": 1605945033652,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "vPNLTNLWQwDX"
   },
   "outputs": [],
   "source": [
    "def server_optimizer_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=SERVER_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 107188,
     "status": "ok",
     "timestamp": 1605945033655,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "JEPK0AlzujvZ"
   },
   "outputs": [],
   "source": [
    "def client_optimizer_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=CLIENT_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 213106,
     "status": "ok",
     "timestamp": 1605945139584,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "qBzCiCkWFQxW",
    "outputId": "3c4742e0-33c6-44a3-86ab-97b9715ac290"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/operators/control_flow.py:565: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/operators/control_flow.py:565: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
     ]
    }
   ],
   "source": [
    "iterative_process = fedavg.build_federated_averaging_process(\n",
    "    model_fn=tff_model_fn,\n",
    "    model_input_spec=example_dataset.element_spec,\n",
    "    initial_trainable_weights=mobilebert_pretrained_trainable_weights,\n",
    "    initial_non_trainable_weights=mobilebert_pretrained_non_trainable_weights,\n",
    "    server_optimizer_fn=server_optimizer_fn, \n",
    "    client_optimizer_fn=client_optimizer_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 230402,
     "status": "ok",
     "timestamp": 1605945156892,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "yGAWSNTksOmF"
   },
   "outputs": [],
   "source": [
    "server_state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 238219,
     "status": "ok",
     "timestamp": 1605945164720,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "qWGC89ZVWt1c"
   },
   "outputs": [],
   "source": [
    "model_final = tff_model_fn()\n",
    "metric_test = utils.MaskedLMCrossEntropy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oqCXFc7gFQxl",
    "outputId": "a14216a7-e7a6-4425-ab30-3574b80427b2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosing clients to use for training...\n",
      "Training clients selection complete.\n",
      "Round 0 start!\n",
      "Client 9256 : updated the model with server message.\n",
      "Client 9256 : training start.\n",
      "Client 16956 : updated the model with server message.\n",
      "Client 16956 : training start.\n",
      "Client 25174 : updated the model with server message.\n",
      "Client 25174 : training start.\n",
      "Client 16956 : 8 processed\n",
      "Client 16956 : 16 processed\n",
      "Client 16956 : 24 processed\n",
      "Client 16956 : 32 processed\n",
      "Client 16956 : 40 processed\n",
      "Client 16956 : 48 processed\n",
      "Client 16956 : 56 processed\n",
      "Client 16956 : 64 processed\n",
      "Client 16956 : 72 processed\n",
      "Client 16956 : 80 processed\n",
      "Client 16956 : 88 processed\n",
      "Client 16956 : 96 processed\n",
      "Client 16956 : 104 processed\n",
      "Client 16956 : 112 processed\n",
      "Client 16956 : 120 processed\n"
     ]
    }
   ],
   "source": [
    "for round_num in range(TOTAL_ROUNDS):\n",
    "\n",
    "    # Training clients selection\n",
    "    print(\"Choosing clients to use for training...\")\n",
    "\n",
    "    sampled_clients = np.random.choice(\n",
    "        train_client_data.client_ids,\n",
    "        size=TRAIN_CLIENTS_PER_ROUND,\n",
    "        replace=False)\n",
    "\n",
    "    sampled_train_data = [\n",
    "        train_client_data.create_tf_dataset_for_client(client)\n",
    "        for client in sampled_clients\n",
    "    ]\n",
    "\n",
    "    print(\"Training clients selection complete.\")\n",
    "\n",
    "    # FedAvg\n",
    "    print(f'Round {round_num} start!')\n",
    "\n",
    "    server_state, train_metrics = iterative_process.next(server_state, sampled_train_data)\n",
    "\n",
    "    print(f'Round {round_num} training loss: {train_metrics}')\n",
    "\n",
    "    # Evaluation\n",
    "    if round_num % ROUNDS_PER_EVAL == 0:\n",
    "        model_final.from_weights(server_state.model_weights)\n",
    "\n",
    "        # Test dataset generation for this round\n",
    "        print(\"Sampling clients to use for testing...\")\n",
    "\n",
    "        sampled_test_clients = np.random.choice(\n",
    "            test_client_data.client_ids,\n",
    "            size=TEST_CLIENTS_PER_ROUND,\n",
    "            replace=False)\n",
    "\n",
    "        sampled_test_data = [\n",
    "            test_client_data.create_tf_dataset_for_client(client)\n",
    "            for client in sampled_test_clients\n",
    "        ]\n",
    "\n",
    "        sampled_test_data_merged = sampled_test_data[0]\n",
    "\n",
    "        if len(sampled_test_data) > 1:\n",
    "            for client_test in range(1, len(sampled_test_data)):\n",
    "                sampled_test_data_merged.concatenate(sampled_test_data[client_test])\n",
    "\n",
    "        print(\"Test clients selected.\")\n",
    "\n",
    "        metric_validation = utils.keras_evaluate(model_final.keras_model, sampled_test_data_merged, metric_test)\n",
    "\n",
    "        print(f'Round {round_num} validation metric: {metric_validation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qtB10S5tUQ1F"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mobilebert_mlm_shakespeare_fedavg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
