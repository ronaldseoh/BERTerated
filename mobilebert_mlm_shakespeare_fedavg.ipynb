{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6qruq9ZFQsN"
   },
   "source": [
    "# Fine-Tuning MobileBERT with Federated Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 635,
     "status": "ok",
     "timestamp": 1605152620247,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "-AgOn_qCFQsk"
   },
   "outputs": [],
   "source": [
    "# Copyright 2020, The TensorFlow Federated Authors.\n",
    "# Copyright 2020, Ronald Seoh\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zUGmvEbFQts"
   },
   "source": [
    "## Google Colab settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 112925,
     "status": "ok",
     "timestamp": 1605152732549,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "_1nBG9qaFQt9",
    "outputId": "3c8338ce-979b-4566-8b83-99d19ea13fdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-federated==0.17.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/54/900d99d3cff21b6a570281b51f4878a745c0eece7732bb7fc26eee61ef57/tensorflow_federated-0.17.0-py2.py3-none-any.whl (517kB)\n",
      "\u001b[K     |████████████████████████████████| 522kB 10.3MB/s \n",
      "\u001b[?25hCollecting tensorflow-text==2.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/b2/2dbd90b93913afd07e6101b8b84327c401c394e60141c1e98590038060b3/tensorflow_text-2.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.6MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6MB 21.8MB/s \n",
      "\u001b[?25hCollecting transformers==3.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 45.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow~=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0) (2.3.0)\n",
      "Requirement already satisfied: retrying~=1.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0) (1.3.3)\n",
      "Collecting tensorflow-privacy~=0.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/ae/7db0dcf76a746314a174578a7b99ff098b40b908c4c693a955a2bbc0127b/tensorflow_privacy-0.5.1-py3-none-any.whl (149kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 51.5MB/s \n",
      "\u001b[?25hCollecting grpcio~=1.29.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/04/2b67f0a3645481235d5547891fd0e45e384f1ae5676788f24a7c8735b4e9/grpcio-1.29.0-cp36-cp36m-manylinux2010_x86_64.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 46.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0) (0.1.5)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0) (2.10.0)\n",
      "Collecting attrs~=19.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/db/4313ab3be961f7a763066401fb77f7748373b6094076ae2bda2806988af6/attrs-19.3.0-py2.py3-none-any.whl\n",
      "Collecting tensorflow-model-optimization~=0.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/cc/4b0831f492396f03a4563cc749ad94cbf7af986aaa7a7d89e5979029ce5c/tensorflow_model_optimization-0.4.1-py2.py3-none-any.whl (172kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 57.0MB/s \n",
      "\u001b[?25hCollecting absl-py~=0.9.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 55.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy~=1.18.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0) (1.18.5)\n",
      "Collecting tensorflow-addons~=0.11.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/f8/d6fca180c123f2851035c4493690662ebdad0849a9059d56035434bff5c9/tensorflow_addons-0.11.2-cp36-cp36m-manylinux2010_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 47.0MB/s \n",
      "\u001b[?25hCollecting semantic-version~=2.8.5\n",
      "  Downloading https://files.pythonhosted.org/packages/a5/15/00ef3b7888a10363b7c402350eda3acf395ff05bebae312d1296e528516a/semantic_version-2.8.5-py2.py3-none-any.whl\n",
      "Collecting cachetools~=3.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: portpicker~=1.3.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0) (1.3.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.12.4)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 52.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2019.12.20)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 47.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (20.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.0.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2.23.0)\n",
      "Collecting tokenizers==0.9.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 45.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (2.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (2.3.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (1.1.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (0.3.3)\n",
      "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (1.4.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (0.35.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0) (1.6.3)\n",
      "Requirement already satisfied: mpmath in /usr/local/lib/python3.6/dist-packages (from tensorflow-privacy~=0.5.0->tensorflow-federated==0.17.0) (1.1.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons~=0.11.1->tensorflow-federated==0.17.0) (2.7.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.4.0) (50.3.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (0.17.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.4.0) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2.10)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (1.7.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (1.17.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (0.4.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (3.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0) (3.4.0)\n",
      "Building wheels for collected packages: absl-py, sacremoses\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for absl-py: filename=absl_py-0.9.0-cp36-none-any.whl size=121933 sha256=e72ef115fcb82032df7a1984c5d8b996e933de8fc433cb9b1301bb2b0801d9de\n",
      "  Stored in directory: /root/.cache/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=33aefc38cf437a6d8541dfd99c1a173c4094c14dd6d6e4c5e14813e0f622ab97\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built absl-py sacremoses\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorflow-privacy, grpcio, attrs, tensorflow-model-optimization, absl-py, tensorflow-addons, semantic-version, cachetools, tensorflow-federated, tensorflow-text, sentencepiece, sacremoses, tokenizers, transformers\n",
      "  Found existing installation: tensorflow-privacy 0.2.2\n",
      "    Uninstalling tensorflow-privacy-0.2.2:\n",
      "      Successfully uninstalled tensorflow-privacy-0.2.2\n",
      "  Found existing installation: grpcio 1.33.2\n",
      "    Uninstalling grpcio-1.33.2:\n",
      "      Successfully uninstalled grpcio-1.33.2\n",
      "  Found existing installation: attrs 20.2.0\n",
      "    Uninstalling attrs-20.2.0:\n",
      "      Successfully uninstalled attrs-20.2.0\n",
      "  Found existing installation: absl-py 0.10.0\n",
      "    Uninstalling absl-py-0.10.0:\n",
      "      Successfully uninstalled absl-py-0.10.0\n",
      "  Found existing installation: tensorflow-addons 0.8.3\n",
      "    Uninstalling tensorflow-addons-0.8.3:\n",
      "      Successfully uninstalled tensorflow-addons-0.8.3\n",
      "  Found existing installation: cachetools 4.1.1\n",
      "    Uninstalling cachetools-4.1.1:\n",
      "      Successfully uninstalled cachetools-4.1.1\n",
      "Successfully installed absl-py-0.9.0 attrs-19.3.0 cachetools-3.1.1 grpcio-1.29.0 sacremoses-0.0.43 semantic-version-2.8.5 sentencepiece-0.1.94 tensorflow-addons-0.11.2 tensorflow-federated-0.17.0 tensorflow-model-optimization-0.4.1 tensorflow-privacy-0.5.1 tensorflow-text-2.3.0 tokenizers-0.9.2 transformers-3.4.0\n",
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/Colab Notebooks/BERTerated\n",
      "LICENSE\t\t\t\t\t   simple_fedavg_tff.py\n",
      "mobilebert_mlm_shakespeare_fedavg.ipynb    simple_fedavg_tf.py\n",
      "mobilebert_mlm_stackoverflow_fedavg.ipynb  tff_cache\n",
      "__pycache__\t\t\t\t   transformers_cache\n",
      "README.md\t\t\t\t   utils.py\n",
      "simple_fedavg_test.py\n"
     ]
    }
   ],
   "source": [
    "# Use Google Colab\n",
    "use_colab = True\n",
    "\n",
    "# Is this notebook running on Colab?\n",
    "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
    "# should be available in this environment\n",
    "\n",
    "# Previous version used importlib, but we could do the same thing with\n",
    "# just attempting to import google.colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab_available = True\n",
    "except:\n",
    "    colab_available = False\n",
    "\n",
    "if use_colab and colab_available:\n",
    "    # If there's a package I need to install separately, do it here\n",
    "    !pip install tensorflow-federated==0.17.0 tensorflow-text==2.3.0 transformers==3.4.0\n",
    "\n",
    "    # Mount Google Drive root directory\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # cd to the appropriate working directory under my Google Drive\n",
    "    %cd 'drive/My Drive/Colab Notebooks/BERTerated'\n",
    "    \n",
    "    # List the directory contents\n",
    "    !ls\n",
    "\n",
    "# IPython reloading magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F16eB2w-FQuw"
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 124783,
     "status": "ok",
     "timestamp": 1605152744419,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "k_SnruV2FQu0",
    "outputId": "19e78c18-25c9-455f-d06a-e80a59d39964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'Hello, World!'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import tensorflow_text as tftext\n",
    "import transformers\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import simple_fedavg_tf\n",
    "import simple_fedavg_tff\n",
    "import utils\n",
    "\n",
    "# Random seed settings\n",
    "random_seed = 692\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "# Tensorflow GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Test the TFF is working:\n",
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 124773,
     "status": "ok",
     "timestamp": 1605152744422,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "FHYxELiQFQvI",
    "outputId": "effd324c-2119-4279-bd1d-d3d1f735fa12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.9 (default, Oct  8 2020, 12:12:24) \n",
      "[GCC 8.4.0]\n",
      "NumPy version: 1.18.5\n",
      "TensorFlow version: 2.3.0\n",
      "TensorFlow Federated version: 0.17.0\n",
      "Transformers version: 3.4.0\n"
     ]
    }
   ],
   "source": [
    "# Print version information\n",
    "print(\"Python version: \" + sys.version)\n",
    "print(\"NumPy version: \" + np.__version__)\n",
    "print(\"TensorFlow version: \" + tf.__version__)\n",
    "print(\"TensorFlow Federated version: \" + tff.__version__)\n",
    "print(\"Transformers version: \" + transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYXMEboAFQvd"
   },
   "source": [
    "## Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 124764,
     "status": "ok",
     "timestamp": 1605152744425,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "M071lqOQFQvi"
   },
   "outputs": [],
   "source": [
    "TOTAL_ROUNDS = 2 # Number of total training rounds\n",
    "ROUNDS_PER_EVAL = 1 # How often to evaluate\n",
    "TRAIN_CLIENTS_PER_ROUND = 1 # How many clients to sample per round.\n",
    "TEST_CLIENTS_PER_ROUND = 1 # How many clients to sample per round for test data\n",
    "CLIENT_EPOCHS_PER_ROUND = 1 # Number of epochs in the client to take per round.\n",
    "BATCH_SIZE = 3 # Batch size used on the client.\n",
    "BUFFER_SIZE = 5  # For dataset shuffling\n",
    "TEST_BATCH_SIZE = 5 # Minibatch size of test data.\n",
    "SEQ_LENGTH = 64 # Maximum length of input token sequence for BERT.\n",
    "\n",
    "# Optimizer configuration\n",
    "SERVER_LEARNING_RATE = 1.0 # Server learning rate.\n",
    "CLIENT_LEARNING_RATE = 0.1 # Client learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-tHcHX0FQvz"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 126078,
     "status": "ok",
     "timestamp": 1605152745746,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "cVkK1BV9FQv3"
   },
   "outputs": [],
   "source": [
    "train_client_data, test_client_data = tff.simulation.datasets.shakespeare.load_data(cache_dir='./tff_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 126341,
     "status": "ok",
     "timestamp": 1605152746015,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "ZXmJYQbeFQwG"
   },
   "outputs": [],
   "source": [
    "mobilebert_tokenizer = transformers.MobileBertTokenizer.from_pretrained(\n",
    "    'google/mobilebert-uncased', cache_dir='./transformers_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 126336,
     "status": "ok",
     "timestamp": 1605152746017,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "8c7S9s9qRlsi"
   },
   "outputs": [],
   "source": [
    "# Imitate transformers tokenizer with TF.Text Tokenizer\n",
    "mobilebert_vocab_lookup_table = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=list(mobilebert_tokenizer.vocab.keys()),\n",
    "        values=tf.constant(list(mobilebert_tokenizer.vocab.values()), dtype=tf.int64)),\n",
    "    default_value=0)\n",
    "\n",
    "mobilebert_tokenizer_tf_text = tftext.BertTokenizer(\n",
    "    vocab_lookup_table=mobilebert_vocab_lookup_table, lower_case=True, split_unknown_characters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "executionInfo": {
     "elapsed": 126755,
     "status": "ok",
     "timestamp": 1605152746445,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "5iwW2jo3TFUt",
    "outputId": "c1ee9680-61fb-4242-b0f6-cc49916144bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 5 1], shape=(3,), dtype=int32)\n",
      "tf.Tensor([[2023 2003 1037 3231 1012]], shape=(1, 5), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'this is a test.'"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if our new tokenizer works\n",
    "ttt = mobilebert_tokenizer_tf_text.tokenize(\"This is a test.\")\n",
    "print(tf.shape(ttt.to_tensor()))\n",
    "print(tf.squeeze(ttt.to_tensor(), axis=-1))\n",
    "mobilebert_tokenizer.decode(tf.squeeze(ttt, axis=-1).to_list()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 126750,
     "status": "ok",
     "timestamp": 1605152746448,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "ywaR8paPg4eO"
   },
   "outputs": [],
   "source": [
    "mobilebert_special_ids_mask_table = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=tf.constant(mobilebert_tokenizer.all_special_ids, dtype=tf.int64),\n",
    "        values=tf.constant(1, dtype=tf.int64, shape=len(mobilebert_tokenizer.all_special_ids)),\n",
    "        key_dtype=tf.int64, value_dtype=tf.int64),\n",
    "    default_value=tf.constant(0, dtype=tf.int64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sfMNvpmFQwW"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 126745,
     "status": "ok",
     "timestamp": 1605152746450,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "oIOw1zG1RfnU"
   },
   "outputs": [],
   "source": [
    "# Based on the answers from\n",
    "# https://stackoverflow.com/questions/42334646/tensorflow-pad-unknown-size-tensor-to-a-specific-size/51936821#51936821\n",
    "def dynamic_padding(inp, min_size, constant_values):\n",
    "\n",
    "    pad_size = min_size - tf.shape(inp)[1]\n",
    "    paddings = [[0,0], [0, pad_size]] # assign here, during graph execution\n",
    "\n",
    "    return tf.pad(inp, paddings, constant_values=constant_values)\n",
    "\n",
    "# New preprocessing steps based on TF.text tokenizer\n",
    "def tokenize_and_mask(x):\n",
    "    # TF.text tokenizer returns RaggedTensor. Convert this to a regular tensor.\n",
    "    # Note: In the third dimension, 2nd and 3rd indexes contain some sort of offset information,\n",
    "    # which we will ignore for now.\n",
    "    tokenized = mobilebert_tokenizer_tf_text.tokenize(tf.reshape(x['snippets'], shape=[1])).to_tensor()[:, :, 0]\n",
    "\n",
    "    # Add special tokens: [CLS]\n",
    "    cls_tensor_for_tokenized = tf.constant(mobilebert_tokenizer.cls_token_id, shape=[len(x), 1], dtype=tf.int64)\n",
    "    tokenized_with_special_tokens = tf.concat([cls_tensor_for_tokenized, tokenized], axis=1)\n",
    "\n",
    "    # Truncate if the sequence is already longer than SEQ_LENGTH\n",
    "    tokenized_with_special_tokens = tf.cond(\n",
    "        tf.greater_equal(tf.shape(tokenized_with_special_tokens)[1], SEQ_LENGTH),\n",
    "        true_fn=lambda: tokenized_with_special_tokens[:, 0:SEQ_LENGTH-1],\n",
    "        false_fn=lambda: tokenized_with_special_tokens)     \n",
    "\n",
    "    # Add special tokens: [SEP]\n",
    "    sep_tensor_for_tokenized = tf.constant(mobilebert_tokenizer.sep_token_id, shape=[len(x), 1], dtype=tf.int64)\n",
    "    tokenized_with_special_tokens = tf.concat([tokenized_with_special_tokens, sep_tensor_for_tokenized], axis=1)\n",
    "\n",
    "    # Padding with [PAD]\n",
    "    # Final sequence should have the length of SEQ_LENGTH\n",
    "    # Pad only if necessary\n",
    "    tokenized_with_special_tokens = tf.cond(\n",
    "        tf.less(tf.shape(tokenized_with_special_tokens)[1], SEQ_LENGTH),\n",
    "        true_fn=lambda: dynamic_padding(tokenized_with_special_tokens, SEQ_LENGTH, mobilebert_tokenizer.pad_token_id),\n",
    "        false_fn=lambda: tokenized_with_special_tokens)  \n",
    "\n",
    "    # Random masking for the BERT MLM\n",
    "    masked, labels = utils.get_masked_input_and_labels(\n",
    "        tokenized_with_special_tokens,\n",
    "        mobilebert_vocab_lookup_table,\n",
    "        mobilebert_special_ids_mask_table,\n",
    "        tf.constant(mobilebert_tokenizer.mask_token_id, dtype=tf.int64))\n",
    "\n",
    "    # Squeeze out the first dimension\n",
    "    masked = tf.squeeze(masked)\n",
    "    labels = tf.squeeze(labels)\n",
    "\n",
    "    # Manually settting the shape here so that TensorFlow graph\n",
    "    # could know the sizes in advnace\n",
    "    masked.set_shape(SEQ_LENGTH)\n",
    "    labels.set_shape(SEQ_LENGTH)\n",
    "    \n",
    "    return masked, labels\n",
    "\n",
    "def preprocess_for_train(train_dataset):\n",
    "    return (\n",
    "        # Filter out empty strings\n",
    "        train_dataset.filter(lambda x: tf.strings.length(x['snippets']) > 0)\n",
    "        # Tokenize each samples using MobileBERT tokenizer\n",
    "        .map(tokenize_and_mask)\n",
    "        # Shuffle\n",
    "        .shuffle(BUFFER_SIZE)\n",
    "        # Repeat to make each client train multiple epochs\n",
    "        .repeat(count=CLIENT_EPOCHS_PER_ROUND)\n",
    "        # Form minibatches\n",
    "        # Use drop_remainder=True to force the batch size to be exactly BATCH_SIZE\n",
    "        # and make the shape **exactly** (BATCH_SIZE, SEQ_LENGTH)\n",
    "        .batch(BATCH_SIZE, drop_remainder=True))\n",
    "    \n",
    "def preprocess_for_test(test_dataset):\n",
    "    return (\n",
    "        # Filter out empty strings\n",
    "        test_dataset.filter(lambda x: tf.strings.length(x['snippets']) > 0)\n",
    "        # Tokenize each samples using MobileBERT tokenizer\n",
    "        .map(tokenize_and_mask)\n",
    "        # Shuffle\n",
    "        .shuffle(BUFFER_SIZE)\n",
    "        # Form minibatches\n",
    "        # Use drop_remainder=True to force the batch size to be exactly TEST_BATCH_SIZE\n",
    "        # and make the shape **exactly** (TEST_BATCH_SIZE, SEQ_LENGTH)\n",
    "        .batch(TEST_BATCH_SIZE, drop_remainder=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 130264,
     "status": "ok",
     "timestamp": 1605152749975,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "zMIo2trUC7F7",
    "outputId": "94fa83c9-3015-4e9a-daeb-c645322f88ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting LookupTableFindV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting LookupTableFindV2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/BERTerated/utils.py:30: Bernoulli.__init__ (from tensorflow.python.ops.distributions.bernoulli) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/BERTerated/utils.py:30: Bernoulli.__init__ (from tensorflow.python.ops.distributions.bernoulli) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/bernoulli.py:97: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/bernoulli.py:97: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting LookupTableFindV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting LookupTableFindV2\n"
     ]
    }
   ],
   "source": [
    "train_client_data = train_client_data.preprocess(preprocess_fn=preprocess_for_train)\n",
    "test_client_data = test_client_data.preprocess(preprocess_fn=preprocess_for_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 130547,
     "status": "ok",
     "timestamp": 1605152750266,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "b8NzsgjFFQwp",
    "outputId": "cc772c02-3773-453a-e9b8-f10246913697"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting LookupTableFindV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting LookupTableFindV2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(3, 64), dtype=tf.int64, name=None), TensorSpec(shape=(3, 64), dtype=tf.int64, name=None))\n"
     ]
    }
   ],
   "source": [
    "# Create a test client dataset, just to get the element_spec info\n",
    "example_dataset = train_client_data.create_tf_dataset_for_client('THE_TRAGEDY_OF_KING_LEAR_KING')\n",
    "print(example_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 130787,
     "status": "ok",
     "timestamp": 1605152750517,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "qa-KoFpz1jbt",
    "outputId": "5f6f8ca4-3441-4b07-8a72-8985108ab913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  101  3521   999   102     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  2129 27092  2115  9995  1029   102     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  2007  1037 15514 21916  1997   103  1010  1037  2158  1999  2035\n",
      "   1996  2088  1005   103  2047  4827   103  1010  2008  6045  1037 12927\n",
      "   1997 15672  1999  2010  4167  1025  2028  2040  1996   103  1997  2010\n",
      "    103   103  4416 11089 16806  2066  4372  9396  1025  1037  2158  1997\n",
      "  13711  1010  3183  2157  1998  3308  2031  4900  2004 20887  1997   103\n",
      "  19306  1012  2023   102]], shape=(3, 64), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[ -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  -100  -100  -100  -100  3577  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  1055  -100  -100  8461  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  2189  -100  -100\n",
      "   2219 15784  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  4900  -100  -100  -100  2037\n",
      "   -100  -100  -100  -100]], shape=(3, 64), dtype=int64)\n",
      "['[CLS] peace! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] how fares your majesty? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', \"[CLS] with a refined traveller of [MASK], a man in all the world'[MASK] new fashion [MASK], that hat a mint of phrases in his brain ; one who the [MASK] of his [MASK] [MASK] tongue dot ravi like en harmony ; a man of complement, whom right and wrong have chose as umpire of [MASK] mutiny. this [SEP]\"]\n",
      "tf.Tensor(\n",
      "[[  101   103 20588  1005  2417  2588  2256 11655 16623  1010   103  2059\n",
      "   4519  2149  1999  1996 29591   103  2331  1025  2043   103  8741  1997\n",
      "   2522 16475  2051  1010   103   103 26911  1997  2023  2556  3052  2089\n",
      "   4965  2008  6225  2029  4618  7151  2010  8040   103  1055 10326  3341\n",
      "    103  1998  2191  2149 15891  1997  2035 12715  1012  3568  1010  9191\n",
      "  25466  1011  2005   102]\n",
      " [  101  1031   103  1033  1005  2307   103  1010  1996  2057  1005  1055\n",
      "   3580  1998   103   102     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  2023  1029  2106  2017  2963  1996 16413  1029   102     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]], shape=(3, 64), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[ -100  2444  -100  -100  -100  -100  -100  -100  -100  -100  1998  -100\n",
      "   -100  -100  -100  -100  -100  1997  -100  -100  -100  1010  -100  -100\n",
      "   -100  -100  -100  -100 16215  1005  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  1005  -100  -100  -100\n",
      "   1010  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  9631  -100  -100  -100  4112  -100  -100  -100  -100  -100\n",
      "   -100  -100  7082  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]], shape=(3, 64), dtype=int64)\n",
      "[\"[CLS] [MASK] regis'red upon our bra tombs, [MASK] then grace us in the disgrace [MASK] death ; when [MASK] spite of co dev time, [MASK] [MASK] endeavour of this present breath may buy that honour which shall bat his sc [MASK] s keen edge [MASK] and make us heirs of all eternity. therefore, brave conqueror - for [SEP]\", \"[CLS] [ [MASK] ]'great [MASK], the we's vice and [MASK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", '[CLS] this? did you hear the proclamation? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "tf.Tensor(\n",
      "[[  101  2070  4189  8016  1012 21658  1010   103  2001  7545   102     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  1045  2354  2014  2011  2023 13713  2006  2014 10353  1012  2022\n",
      "    103   103  2097  9467  2149   103  2292   103  2025  3921  1012   102\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  1045  2572  2190 22512  1005  1040  2007  2008  1012   103   103\n",
      "  23705   103  1033   102     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]], shape=(3, 64), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[-100 -100 -100 -100 -100 -100 -100 1045 -100 1012 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 1010 2027\n",
      "  -100 -100 -100 1025 -100 2068 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100 -100 -100 -100 -100 -100 -100 -100 -100 -100 1031 2027 -100 4237\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100]], shape=(3, 64), dtype=int64)\n",
      "['[CLS] some fair excuse. madam, [MASK] was brings [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] i knew her by this jewel on her sleeve. be [MASK] [MASK] will shame us [MASK] let [MASK] not approach. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', \"[CLS] i am best pleas'd with that. [MASK] [MASK] converse [MASK] ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\"]\n",
      "tf.Tensor(\n",
      "[[  101  1005   103  2204   103  2106  1025  2005  1010  2909  1010  2000\n",
      "  10395  2017  5810   103   102     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  2057  2020  4078  1025  2027  1005  2222 12934 12818  2085  2091\n",
      "   1012   102     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101 29536  1010  4408  4231  1010   103   103 15177  3340  1010  2000\n",
      "  12342   103  2216  8044  3718  1010  2588   103 28259   103  1012 20047\n",
      "  21673  2256  5468  2079  2021 29536  2028  2689  1012   102     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]], shape=(3, 64), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[-100 -100 1056 -100 6737 -100 -100 -100 -100 -100 -100 -100 2425 -100\n",
      "  -100 1010 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100 -100 -100 -100 -100 -100 -100 -100 -100 2149 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100 -100 -100 -100 -100 -100 1998 2122 -100 -100 -100 -100 -100 1010\n",
      "  -100 -100 -100 -100 -100 2256 -100 1041 -100 2059 1999 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100]], shape=(3, 64), dtype=int64)\n",
      "[\"[CLS]'[MASK] good [MASK] did ; for, sir, to resolved you plain [MASK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", \"[CLS] we were des ; they'll mock vein now down. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", '[CLS] vo, bright moon, [MASK] [MASK] thy stars, to shine [MASK] those clouds removed, upon [MASK] watery [MASK]. shortesteral our measure do but vo one change. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "tf.Tensor(\n",
      "[[  101  2129   103   999  2054  2003  1999  2017  1029   103   103 15223\n",
      "   7697  2009  1029   102     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  6516  1010  2909   103  2185  1012   102     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  2024  2057 12056  2947  2000 15177   103  1011  3193  1029  3730\n",
      "    999  1059   103  2061  3435  1029   102     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]], shape=(3, 64), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[-100 -100 2085 -100 -100 -100 -100 -100 -100 2339 9998 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100 -100 -100 -100 1010 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100 -100 -100 -100 -100 -100 -100 2058 -100 -100 -100 -100  999 -100\n",
      "  2185 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100]], shape=(3, 64), dtype=int64)\n",
      "['[CLS] how [MASK]! what is in you? [MASK] [MASK] thou tear it? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] hence, sir [MASK] away. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] are we betrayed thus to thy [MASK] - view? soft! w [MASK] so fast? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "tf.Tensor(\n",
      "[[  101  2092  1010  4133  2041  1025  2175  2188  1010  2022  1025 27133\n",
      "   1012   102     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  2000  4257  2039   103  4204  1997  3067  2007  2717  1010  1996\n",
      "   5573   103  1997  2331  2485   103  3067  3239   999  6516   103  2059\n",
      "   1010  2026  2540  2003  1999 15177  7388  1012  2053  1010 21658  1025\n",
      "   2057  2097  3288  2017  2006   103  2126  1012   102     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101   103 24905  1998  2300  1012  1998  2123  2849 30180   103  2115\n",
      "  10684   103   102     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]], shape=(3, 64), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[ -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  -100  -100  2122  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  2192  -100  -100  -100  2039  -100  -100  -100  -100 24308  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  2115  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  2007  -100  -100  -100  -100  -100  -100  -100  4618  2022  -100\n",
      "   -100  1012  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]], shape=(3, 64), dtype=int64)\n",
      "['[CLS] well, sit out ; go home, be ; adi. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] to flat up [MASK] powers of mine with rest, the sudden [MASK] of death close [MASK] mine eye! hence [MASK] then, my heart is in thy breast. no, madam ; we will bring you on [MASK] way. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] [MASK] bran and water. and don armけ [MASK] your keeper [MASK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "tf.Tensor(\n",
      "[[  101  2008  2404  2849  1005  1055  3931  2041  1997  2010  2112   999\n",
      "    103   103   103  1996  4615  1010 23815  2011  2879  1025  9508  1010\n",
      "   3814   103  1998 25739  2035 16889   103  4086 21658  1010  1998  4189\n",
      "   2051  1997  2154   999   102     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101   103  2007 26727  1037  2033   999   102     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  1998  3345  2256 24823  2000 15784 12208  1012  2129  2092  2002\n",
      "   1005  1055  3191  1010  2000  3114  2114  3752   103   102     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]], shape=(3, 64), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[-100 -100 2404 -100 -100 -100 -100 -100 -100 -100 -100 -100 2128 1011\n",
      "  4607 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 1010 -100 -100\n",
      "  -100 -100 1010 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100 6164 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100  999 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100]], shape=(3, 64), dtype=int64)\n",
      "[\"[CLS] that put arm's page out of his part! [MASK] [MASK] [MASK] the princess, ushered by boy ; rosa, maria [MASK] and katharine all hail [MASK] sweet madam, and fair time of day! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", '[CLS] [MASK] with attendants a me! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', \"[CLS] and train our intellect to vain delight. how well he's read, to reason against reading [MASK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\"]\n",
      "tf.Tensor(\n",
      "[[  101  2026  2935  2022   103  2156  2032  5359 19889  1005  9413  1025\n",
      "   9880  2175  8766  1010  8140  1010  2000  2404  1999  3218  2008  2029\n",
      "   2169  2000  2060  6045  2061  6118 10741   103  4654  2332  1010  2146\n",
      "   1010  1998  4241   103  4615   103  6160  2000   103  2457  1997 21260\n",
      "   1012   102     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  1045  2360  2027  4618  2025  2272   103   102     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  1996  2911  2003  2104   103  1010  1998  2182  2016  3310 25933\n",
      "   1012   102     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]], shape=(3, 64), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[-100 -100 -100 -100 1010 -100 -100 -100 1051 -100 -100 -100 1998 -100\n",
      "  2057 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 1012 -100 -100 -100 -100 -100 -100 -100 4189 -100 1010\n",
      "  -100 -100 1996 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100 -100 -100 -100 -100 -100 -100 1012 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100 -100 -100 -100 -100 9498 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100]], shape=(3, 64), dtype=int64)\n",
      "[\"[CLS] my lord be [MASK] see him delivered sweaty'er ; swim go violet, lords, to put in practice that which each to other hat so strongly sworn [MASK] ex king, long, and du [MASK] princess [MASK] welcome to [MASK] court of navarre. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", '[CLS] i say they shall not come [MASK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] the ship is under [MASK], and here she comes ama. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "tf.Tensor(\n",
      "[[  101  4654  2332  1010  8140  1010 23346  2304  4189  2909  1010  2643\n",
      "   3828   103   999  2073   103  1055  1996  4615  1029   102     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  2017  4618  2022   103   103 21658  1010  2000   103  2457  1012\n",
      "    102     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  2054  2360  2017  1010  8140  1029  2339  1010  2023   103  3243\n",
      "   9471  1012   102     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]], shape=(3, 64), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[-100 -100 -100 -100 -100 -100 1998 -100 -100 -100 -100 -100 -100 2017\n",
      "  -100 -100 1005 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100 -100 -100 -100 6160 1010 -100 -100 -100 2026 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100 -100 -100 -100 -100 -100 -100 -100 -100 -100 2001 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100]], shape=(3, 64), dtype=int64)\n",
      "['[CLS] ex king, lords, branching black fair sir, god save [MASK]! where [MASK] s the princess? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] you shall be [MASK] [MASK] madam, to [MASK] court. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] what say you, lords? why, this [MASK] quite forgot. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "tf.Tensor(\n",
      "[[  101  2097  2017   103  2023  3661  2007  3086   103   102     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101  2059  2681  2023 11834  1025  1998  1010   103 24420  1010  2085\n",
      "   6011   102     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [  101 15223  7226  1005  2358  2033 11693  1025  2023 12858  2003  2025\n",
      "   4326   103  2097  2017  2025  3153  1029  2129  2272  2017  2947   327\n",
      "   1029   102     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]], shape=(3, 64), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[ -100  -100  -100  2963  -100  -100  -100  -100  1029  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  -100  -100  -100  -100  -100  -100  2204  2022  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ -100  -100  7226  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  1012  -100  -100  -100  -100  -100  -100  -100  -100  -100 24211\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]], shape=(3, 64), dtype=int64)\n",
      "['[CLS] will you [MASK] this letter with attention [MASK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] then leave this chat ; and, [MASK] throttle, now prove [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', \"[CLS] thou bid'st me beg ; this begging is not strange [MASK] will you not dance? how come you thus [unused322]? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\"]\n"
     ]
    }
   ],
   "source": [
    "# Did the random masking go well?\n",
    "for example_input, example_labels in example_dataset.take(10):\n",
    "    print(example_input)\n",
    "    print(example_labels)\n",
    "\n",
    "    print(mobilebert_tokenizer.batch_decode(tf.squeeze(example_input).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_o5NZpuzFQw7"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 138396,
     "status": "ok",
     "timestamp": 1605152758135,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "2kRecwJPFQw-",
    "outputId": "54b651b2-25fa-4e9b-8f34-048a57bff8f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/mobilebert-uncased were not used when initializing TFMobileBertForMaskedLM: ['seq_relationship___cls', 'predictions___cls']\n",
      "- This IS expected if you are initializing TFMobileBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFMobileBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFMobileBertForMaskedLM were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['mlm___cls']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "def tff_model_fn():\n",
    "    \"\"\"Constructs a fully initialized model for use in federated averaging.\"\"\"\n",
    "    keras_model = transformers.TFMobileBertForMaskedLM.from_pretrained(\n",
    "        'google/mobilebert-uncased', cache_dir='./transformers_cache')\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    return simple_fedavg_tf.KerasModelWrapper(keras_model, example_dataset.element_spec, loss)\n",
    "\n",
    "model = tff_model_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qM6T_Mp8FQxQ"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXwPdo-_Qrsk"
   },
   "source": [
    "### Training setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 138393,
     "status": "ok",
     "timestamp": 1605152758142,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "vPNLTNLWQwDX"
   },
   "outputs": [],
   "source": [
    "def server_optimizer_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=SERVER_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 138388,
     "status": "ok",
     "timestamp": 1605152758146,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "JEPK0AlzujvZ"
   },
   "outputs": [],
   "source": [
    "def client_optimizer_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=CLIENT_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 288769,
     "status": "ok",
     "timestamp": 1605152908536,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "qBzCiCkWFQxW",
    "outputId": "94f84bcb-351b-4f33-a5f6-25a83429aeb8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/mobilebert-uncased were not used when initializing TFMobileBertForMaskedLM: ['seq_relationship___cls', 'predictions___cls']\n",
      "- This IS expected if you are initializing TFMobileBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFMobileBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFMobileBertForMaskedLM were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['mlm___cls']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some layers from the model checkpoint at google/mobilebert-uncased were not used when initializing TFMobileBertForMaskedLM: ['seq_relationship___cls', 'predictions___cls']\n",
      "- This IS expected if you are initializing TFMobileBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFMobileBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFMobileBertForMaskedLM were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['mlm___cls']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some layers from the model checkpoint at google/mobilebert-uncased were not used when initializing TFMobileBertForMaskedLM: ['seq_relationship___cls', 'predictions___cls']\n",
      "- This IS expected if you are initializing TFMobileBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFMobileBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFMobileBertForMaskedLM were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['mlm___cls']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some layers from the model checkpoint at google/mobilebert-uncased were not used when initializing TFMobileBertForMaskedLM: ['seq_relationship___cls', 'predictions___cls']\n",
      "- This IS expected if you are initializing TFMobileBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFMobileBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFMobileBertForMaskedLM were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['mlm___cls']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/operators/control_flow.py:565: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/operators/control_flow.py:565: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
     ]
    }
   ],
   "source": [
    "iterative_process = simple_fedavg_tff.build_federated_averaging_process(\n",
    "    tff_model_fn, server_optimizer_fn, client_optimizer_fn)\n",
    "\n",
    "server_state = iterative_process.initialize()\n",
    "\n",
    "metric = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "executionInfo": {
     "elapsed": 521083,
     "status": "error",
     "timestamp": 1605153140861,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "oqCXFc7gFQxl",
    "outputId": "9dad40da-b5c6-48e4-9c73-0909b3b224c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosing clients to use for training...\n",
      "WARNING:tensorflow:Using a while_loop for converting LookupTableFindV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting LookupTableFindV2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosing training clients complete.\n",
      "Round 0 start!\n",
      "Round 0 training loss: nan\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-256d21833b3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Round {round_num} training loss: {train_metrics}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mround_num\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrounds_per_eval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rounds_per_eval' is not defined"
     ]
    }
   ],
   "source": [
    "for round_num in range(TOTAL_ROUNDS):\n",
    "\n",
    "    print(\"Choosing clients to use for training...\")\n",
    "\n",
    "    sampled_clients = np.random.choice(\n",
    "        train_client_data.client_ids,\n",
    "        size=TRAIN_CLIENTS_PER_ROUND,\n",
    "        replace=False)\n",
    "\n",
    "    sampled_train_data = [\n",
    "        train_client_data.create_tf_dataset_for_client(client)\n",
    "        for client in sampled_clients\n",
    "    ]\n",
    "\n",
    "    print(\"Choosing training clients complete.\")\n",
    "\n",
    "    print(f'Round {round_num} start!')\n",
    "\n",
    "    server_state, train_metrics = iterative_process.next(server_state, sampled_train_data)\n",
    "\n",
    "    print(f'Round {round_num} training loss: {train_metrics}')\n",
    "\n",
    "    if round_num % ROUNDS_PER_EVAL == 0:\n",
    "        model.from_weights(server_state.model_weights)\n",
    "\n",
    "        # Test dataset generation for this round\n",
    "        print(\"Sampling clients to use for testing...\")\n",
    "\n",
    "        sampled_test_clients = np.random.choice(\n",
    "            test_client_data.client_ids,\n",
    "            size=TEST_CLIENTS_PER_ROUND,\n",
    "            replace=False)\n",
    "\n",
    "        sampled_test_data = [\n",
    "            test_client_data.create_tf_dataset_for_client(client)\n",
    "            for client in sampled_test_clients\n",
    "        ]\n",
    "\n",
    "        sampled_test_data_merged = sampled_test_data[0]\n",
    "\n",
    "        if len(sampled_test_data) > 1:\n",
    "            for client_test in range(1, len(sampled_test_data)):\n",
    "                sampled_test_data_merged.concatenate(sampled_test_data[1])\n",
    "\n",
    "        print(\"Test clients selected.\")\n",
    "\n",
    "        perplexity_validation = simple_fedavg_tf.keras_evaluate(model.keras_model, sampled_test_data_merged, metric)\n",
    "\n",
    "        print(f'Round {round_num} validation perplexity: {perplexity_validation}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mobilebert_mlm_shakespeare_fedavg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
