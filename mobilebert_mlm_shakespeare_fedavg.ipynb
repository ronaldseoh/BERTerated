{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6qruq9ZFQsN"
   },
   "source": [
    "# Fine-Tuning MobileBERT with Federated Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-AgOn_qCFQsk"
   },
   "outputs": [],
   "source": [
    "# Copyright 2020, The TensorFlow Federated Authors.\n",
    "# Copyright 2020, Ronald Seoh\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zUGmvEbFQts"
   },
   "source": [
    "## Google Colab settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64669,
     "status": "ok",
     "timestamp": 1605115213048,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "_1nBG9qaFQt9",
    "outputId": "881ed6ff-d2ff-4cec-dcc3-ba717d5c422d"
   },
   "outputs": [],
   "source": [
    "# Use Google Colab\n",
    "use_colab = True\n",
    "\n",
    "# Is this notebook running on Colab?\n",
    "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
    "# should be available in this environment\n",
    "\n",
    "# Previous version used importlib, but we could do the same thing with\n",
    "# just attempting to import google.colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab_available = True\n",
    "except:\n",
    "    colab_available = False\n",
    "\n",
    "if use_colab and colab_available:\n",
    "    # If there's a package I need to install separately, do it here\n",
    "    !pip install tensorflow-federated==0.17.0 transformers==3.4.0\n",
    "\n",
    "    # Mount Google Drive root directory\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # cd to the appropriate working directory under my Google Drive\n",
    "    %cd 'drive/My Drive/Colab Notebooks/BERTerated'\n",
    "    \n",
    "    # List the directory contents\n",
    "    !ls\n",
    "\n",
    "# IPython reloading magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F16eB2w-FQuw"
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16359,
     "status": "ok",
     "timestamp": 1605115232756,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "k_SnruV2FQu0",
    "outputId": "da850ba2-9f44-4438-9822-ac6b7c4a284e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import transformers\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import simple_fedavg_tf\n",
    "import simple_fedavg_tff\n",
    "import utils\n",
    "\n",
    "# Random seed settings\n",
    "random_seed = 692\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "# Tensorflow GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Test the TFF is working:\n",
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3322,
     "status": "ok",
     "timestamp": 1605115239522,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "FHYxELiQFQvI",
    "outputId": "950fe7f1-53b4-4037-df5d-1bbcd8f324f6"
   },
   "outputs": [],
   "source": [
    "# Print version information\n",
    "print(\"Python version: \" + sys.version)\n",
    "print(\"NumPy version: \" + np.__version__)\n",
    "print(\"TensorFlow version: \" + tf.__version__)\n",
    "print(\"TensorFlow Federated version: \" + tff.__version__)\n",
    "print(\"Transformers version: \" + transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYXMEboAFQvd"
   },
   "source": [
    "## Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2261,
     "status": "ok",
     "timestamp": 1605115244961,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "M071lqOQFQvi"
   },
   "outputs": [],
   "source": [
    "TOTAL_ROUNDS = 2 # Number of total training rounds\n",
    "ROUNDS_PER_EVAL = 1 # How often to evaluate\n",
    "TRAIN_CLIENTS_PER_ROUND = 2 # How many clients to sample per round.\n",
    "TEST_CLIENTS_PER_ROUND = 2 # How many clients to sample per round for test data\n",
    "CLIENT_EPOCHS_PER_ROUND = 1 # Number of epochs in the client to take per round.\n",
    "BATCH_SIZE = 20 # Batch size used on the client.\n",
    "BUFFER_SIZE = 1000  # For dataset shuffling\n",
    "TEST_BATCH_SIZE = 100 # Minibatch size of test data.\n",
    "SEQ_LENGTH = 128 # Maximum length of input token sequence for BERT.\n",
    "\n",
    "# Optimizer configuration\n",
    "SERVER_LEARNING_RATE = 1.0 # Server learning rate.\n",
    "CLIENT_LEARNING_RATE = 0.1 # Client learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-tHcHX0FQvz"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3140,
     "status": "ok",
     "timestamp": 1605109979483,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "cVkK1BV9FQv3"
   },
   "outputs": [],
   "source": [
    "train_client_data, test_client_data = tff.simulation.datasets.shakespeare.load_data(cache_dir='./tff_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4177,
     "status": "ok",
     "timestamp": 1605114249929,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "ZXmJYQbeFQwG"
   },
   "outputs": [],
   "source": [
    "mobilebert_tokenizer = transformers.MobileBertTokenizer.from_pretrained(\n",
    "    'google/mobilebert-uncased', cache_dir='./transformers_cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sfMNvpmFQwW"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1842,
     "status": "ok",
     "timestamp": 1605114264854,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "vALOJEukFQwZ"
   },
   "outputs": [],
   "source": [
    "# Codes based on the tips from\n",
    "# https://www.tensorflow.org/federated/tutorials/federated_learning_for_text_generation\n",
    "# https://stackoverflow.com/questions/61555097/mapping-text-data-through-huggingface-tokenizer\n",
    "# https://stackoverflow.com/questions/61022109/how-to-return-a-dictionary-of-tensors-from-tf-py-function\n",
    "# https://stackoverflow.com/questions/42590431/output-from-tensorflow-py-func-has-unknown-rank-shape?noredirect=1\n",
    "def tokenize_and_mask(x):\n",
    "    tokenized = mobilebert_tokenizer.encode(\n",
    "        tf.compat.as_str(x.numpy()),\n",
    "        add_special_tokens=True, padding='max_length', max_length=SEQ_LENGTH,\n",
    "        return_tensors='tf')\n",
    "    \n",
    "    masked, labels = utils.get_masked_input_and_labels(tokenized, mobilebert_tokenizer)\n",
    "    \n",
    "    return masked, labels\n",
    "\n",
    "def tf_tokenize(x):\n",
    "    masked, labels = tf.py_function(\n",
    "        func=tokenize_and_mask, inp=[x['snippets']], Tout=[tf.int32, tf.int32])\n",
    "\n",
    "    masked = tf.squeeze(masked)\n",
    "    labels = tf.squeeze(labels)\n",
    "\n",
    "    # Manually settting the shape here so that TensorFlow graph\n",
    "    # could know the sizes in advnace\n",
    "    masked.set_shape(SEQ_LENGTH)\n",
    "    labels.set_shape(SEQ_LENGTH)\n",
    "\n",
    "    return masked, labels\n",
    "\n",
    "def preprocess_for_train(train_dataset):\n",
    "    return (\n",
    "        # Tokenize each samples using MobileBERT tokenizer\n",
    "        train_dataset.map(tf_tokenize)\n",
    "        # Shuffle\n",
    "        .shuffle(BUFFER_SIZE)\n",
    "        # Repeat to make each client train multiple epochs\n",
    "        .repeat(count=CLIENT_EPOCHS_PER_ROUND)\n",
    "        # Form minibatches\n",
    "        # Use drop_remainder=True to force the batch size to be exactly BATCH_SIZE\n",
    "        # and make the shape **exactly** (BATCH_SIZE, SEQ_LENGTH)\n",
    "        .batch(BATCH_SIZE, drop_remainder=True))\n",
    "    \n",
    "def preprocess_for_test(test_dataset):\n",
    "    return (\n",
    "        # Tokenize each samples using MobileBERT tokenizer\n",
    "        test_dataset.map(tf_tokenize)\n",
    "        # Shuffle and form minibatches\n",
    "        # Use drop_remainder=True to force the batch size to be exactly TEST_BATCH_SIZE\n",
    "        # and make the shape **exactly** (TEST_BATCH_SIZE, SEQ_LENGTH)\n",
    "        .shuffle(BUFFER_SIZE).batch(TEST_BATCH_SIZE, drop_remainder=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2713,
     "status": "ok",
     "timestamp": 1605114270651,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "zMIo2trUC7F7"
   },
   "outputs": [],
   "source": [
    "train_client_data = train_client_data.preprocess(preprocess_fn=preprocess_for_train)\n",
    "test_client_data = test_client_data.preprocess(preprocess_fn=preprocess_for_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1692,
     "status": "ok",
     "timestamp": 1605114274203,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "b8NzsgjFFQwp",
    "outputId": "3d01c6f2-cf3c-4a20-c473-0ce27c018c3c"
   },
   "outputs": [],
   "source": [
    "# Create a test client dataset, just to get the element_spec info\n",
    "example_dataset = train_client_data.create_tf_dataset_for_client('THE_TRAGEDY_OF_KING_LEAR_KING')\n",
    "print(example_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_o5NZpuzFQw7"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12255,
     "status": "ok",
     "timestamp": 1605114311236,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "2kRecwJPFQw-",
    "outputId": "c276d41c-7c6e-4200-e227-3ae870ad4615"
   },
   "outputs": [],
   "source": [
    "def tff_model_fn():\n",
    "    \"\"\"Constructs a fully initialized model for use in federated averaging.\"\"\"\n",
    "    keras_model = transformers.TFMobileBertForMaskedLM.from_pretrained(\n",
    "        'google/mobilebert-uncased', cache_dir='./transformers_cache')\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    return simple_fedavg_tf.KerasModelWrapper(keras_model, example_dataset.element_spec, loss)\n",
    "\n",
    "model = tff_model_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qM6T_Mp8FQxQ"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXwPdo-_Qrsk"
   },
   "source": [
    "### Training setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1546,
     "status": "ok",
     "timestamp": 1605114321039,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "vPNLTNLWQwDX"
   },
   "outputs": [],
   "source": [
    "def server_optimizer_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=SERVER_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1478,
     "status": "ok",
     "timestamp": 1605114323698,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "JEPK0AlzujvZ"
   },
   "outputs": [],
   "source": [
    "def client_optimizer_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=CLIENT_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194152,
     "status": "ok",
     "timestamp": 1605114519241,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "qBzCiCkWFQxW",
    "outputId": "e4efe638-f92c-4d2b-a75b-4ad54d4fd0bb"
   },
   "outputs": [],
   "source": [
    "iterative_process = simple_fedavg_tff.build_federated_averaging_process(\n",
    "    tff_model_fn, server_optimizer_fn, client_optimizer_fn)\n",
    "\n",
    "server_state = iterative_process.initialize()\n",
    "\n",
    "metric = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oqCXFc7gFQxl",
    "outputId": "c580af9e-6f7b-4a8a-cf8b-28fcb8b310a5"
   },
   "outputs": [],
   "source": [
    "for round_num in range(TOTAL_ROUNDS):\n",
    "\n",
    "    print(\"Choosing clients to use for training...\")\n",
    "\n",
    "    sampled_clients = np.random.choice(\n",
    "        train_client_data.client_ids,\n",
    "        size=TRAIN_CLIENTS_PER_ROUND,\n",
    "        replace=False)\n",
    "\n",
    "    sampled_train_data = [\n",
    "        train_client_data.create_tf_dataset_for_client(client)\n",
    "        for client in sampled_clients\n",
    "    ]\n",
    "\n",
    "    print(\"Choosing training clients complete.\")\n",
    "\n",
    "    server_state, train_metrics = iterative_process.next(server_state, sampled_train_data)\n",
    "\n",
    "    print(f'Round {round_num} training loss: {train_metrics}')\n",
    "\n",
    "    if round_num % rounds_per_eval == 0:\n",
    "        model.from_weights(server_state.model_weights)\n",
    "\n",
    "        # Test dataset generation for this round\n",
    "        print(\"Sampling clients to use for testing...\")\n",
    "\n",
    "        sampled_test_clients = np.random.choice(\n",
    "            test_client_data.client_ids,\n",
    "            size=TEST_CLIENTS_PER_ROUND,\n",
    "            replace=False)\n",
    "\n",
    "        sampled_test_data = [\n",
    "            test_client_data.create_tf_dataset_for_client(client)\n",
    "            for client in sampled_test_clients\n",
    "        ]\n",
    "\n",
    "        sampled_test_data_merged = sampled_test_data[0]\n",
    "\n",
    "        for client_test in range(1, len(sampled_test_data)):\n",
    "            sampled_test_data_merged.concatenate(sampled_test_data[1])\n",
    "\n",
    "        print(\"Test clients selected.\")\n",
    "\n",
    "        perplexity_validation = simple_fedavg_tf.keras_evaluate(model.keras_model, sampled_test_data_merged, metric)\n",
    "\n",
    "        print(f'Round {round_num} validation perplexity: {perplexity_validation}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bert_fedavg_main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
