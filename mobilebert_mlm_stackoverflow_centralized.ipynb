{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6qruq9ZFQsN"
   },
   "source": [
    "# Further Pre-training MobileBERT MLM with Centralized Training (Stackoverflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-AgOn_qCFQsk"
   },
   "outputs": [],
   "source": [
    "# Copyright 2020, The TensorFlow Federated Authors.\n",
    "# Copyright 2020, Ronald Seoh\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zUGmvEbFQts"
   },
   "source": [
    "## Google Colab settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28538,
     "status": "ok",
     "timestamp": 1605972185553,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "_1nBG9qaFQt9",
    "outputId": "1cd85213-e9a2-41f3-a780-538387ae9ec2"
   },
   "outputs": [],
   "source": [
    "# Use Google Colab\n",
    "use_colab = True\n",
    "\n",
    "# Is this notebook running on Colab?\n",
    "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
    "# should be available in this environment\n",
    "\n",
    "# Previous version used importlib, but we could do the same thing with\n",
    "# just attempting to import google.colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab_available = True\n",
    "except:\n",
    "    colab_available = False\n",
    "\n",
    "if use_colab and colab_available:\n",
    "    # Mount Google Drive root directory\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # cd to the appropriate working directory under my Google Drive\n",
    "    %cd '/content/drive/My Drive/Colab Notebooks/BERTerated'\n",
    "    \n",
    "    # List the directory contents\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython reloading magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21641,
     "status": "ok",
     "timestamp": 1605972208442,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "seTmBYc5EJ7q",
    "outputId": "23227396-6a14-43ba-9e13-68522b2090c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-federated==0.17.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.17.0)\n",
      "Requirement already satisfied: tensorflow-text==2.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (2.3.0)\n",
      "Requirement already satisfied: transformers==3.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (3.4.0)\n",
      "Requirement already satisfied: retrying~=1.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.3.3)\n",
      "Requirement already satisfied: numpy~=1.18.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.18.5)\n",
      "Requirement already satisfied: absl-py~=0.9.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: tensorflow-addons~=0.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (0.11.2)\n",
      "Requirement already satisfied: semantic-version~=2.8.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (2.8.5)\n",
      "Requirement already satisfied: tensorflow-privacy~=0.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (0.5.1)\n",
      "Requirement already satisfied: tensorflow~=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (2.3.1)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (2.10.0)\n",
      "Requirement already satisfied: portpicker~=1.3.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: grpcio~=1.29.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.29.0)\n",
      "Requirement already satisfied: cachetools~=3.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (0.1.5)\n",
      "Requirement already satisfied: attrs~=19.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (19.3.0)\n",
      "Requirement already satisfied: tensorflow-model-optimization~=0.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0->-r requirements.txt (line 3)) (0.9.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0->-r requirements.txt (line 3)) (2020.11.13)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0->-r requirements.txt (line 3)) (3.0.12)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0->-r requirements.txt (line 3)) (0.1.94)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0->-r requirements.txt (line 3)) (3.13.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0->-r requirements.txt (line 3)) (4.52.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0->-r requirements.txt (line 3)) (0.0.43)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0->-r requirements.txt (line 3)) (0.8)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0->-r requirements.txt (line 3)) (2.24.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0->-r requirements.txt (line 3)) (20.4)\n",
      "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from retrying~=1.3.3->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons~=0.11.1->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (2.10.0)\n",
      "Requirement already satisfied: mpmath in /usr/local/lib/python3.6/dist-packages (from tensorflow-privacy~=0.5.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from tensorflow-privacy~=0.5.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.5.4)\n",
      "Requirement already satisfied: tensorflow-estimator>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-privacy~=0.5.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.12.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (0.3.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (0.30.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.4.0->-r requirements.txt (line 3)) (50.3.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0->-r requirements.txt (line 3)) (0.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0->-r requirements.txt (line 3)) (7.1.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 3)) (2.6)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 3)) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 3)) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.4.0->-r requirements.txt (line 3)) (2.4.7)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.22.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (3.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (0.4.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.7.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (4.6)\n",
      "Requirement already satisfied: aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (3.6.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (0.2.8)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (0.4.8)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: multidict<5.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (4.7.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (3.7.4.3)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (3.0.1)\n",
      "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow-federated==0.17.0->-r requirements.txt (line 1)) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F16eB2w-FQuw"
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8763,
     "status": "ok",
     "timestamp": 1605972246385,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "k_SnruV2FQu0",
    "outputId": "35194c2b-6489-4a8d-ca00-eb29dd030e79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'Hello, World!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import datetime\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import tensorflow_text as tf_text\n",
    "import transformers\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import fedavg\n",
    "import fedavg_client\n",
    "import datasets\n",
    "import utils\n",
    "\n",
    "# Random seed settings\n",
    "random_seed = 692\n",
    "random.seed(random_seed) # Python\n",
    "np.random.seed(random_seed) # NumPy\n",
    "tf.random.set_seed(random_seed) # TensorFlow\n",
    "\n",
    "# Tensorflow GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Test if TFF is working\n",
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1441,
     "status": "ok",
     "timestamp": 1605972029405,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "FHYxELiQFQvI",
    "outputId": "f56168dc-67f5-437b-a221-b9001dd7ae1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.9 (default, Jul 17 2020, 12:50:27) \n",
      "[GCC 8.4.0]\n",
      "NumPy version: 1.18.5\n",
      "TensorFlow version: 2.3.1\n",
      "TensorFlow Federated version: 0.17.0\n",
      "Transformers version: 3.4.0\n"
     ]
    }
   ],
   "source": [
    "# Print version information\n",
    "print(\"Python version: \" + sys.version)\n",
    "print(\"NumPy version: \" + np.__version__)\n",
    "print(\"TensorFlow version: \" + tf.__version__)\n",
    "print(\"TensorFlow Federated version: \" + tff.__version__)\n",
    "print(\"Transformers version: \" + transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58457,
     "status": "ok",
     "timestamp": 1605971405497,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "sLvpOpvhEA0E",
    "outputId": "1e37cab1-d945-4356-cfca-d4c5e7b4f9b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 21 21:22:58 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  On   | 00000000:04:00.0 Off |                  N/A |\r\n",
      "|  0%   22C    P2    55W / 250W |  10525MiB / 11178MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1423,
     "status": "ok",
     "timestamp": 1605972322381,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "rYBBpJmhQKUK"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYXMEboAFQvd"
   },
   "source": [
    "## Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1366,
     "status": "ok",
     "timestamp": 1605972324555,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "M071lqOQFQvi"
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_CONFIG = {}\n",
    "\n",
    "EXPERIMENT_CONFIG['TOTAL_ROUNDS'] = 1 # Number of total training rounds\n",
    "EXPERIMENT_CONFIG['ROUNDS_PER_EVAL'] = 1 # How often to evaluate\n",
    "\n",
    "EXPERIMENT_CONFIG['TRAIN_CLIENTS_PER_ROUND'] = 5 # How many clients to sample per round.\n",
    "EXPERIMENT_CONFIG['CLIENT_EPOCHS_PER_ROUND'] = 3\n",
    "\n",
    "# Epochs to train in centralized setting\n",
    "EXPERIMENT_CONFIG['CENTRALIZED_EPOCHS'] = EXPERIMENT_CONFIG['CLIENT_EPOCHS_PER_ROUND'] * EXPERIMENT_CONFIG['TOTAL_ROUNDS']\n",
    "\n",
    "EXPERIMENT_CONFIG['BATCH_SIZE'] = 16 # Batch size used on the client.\n",
    "EXPERIMENT_CONFIG['TEST_BATCH_SIZE'] = 32 # Minibatch size of test data.\n",
    "\n",
    "# Maximum length of input token sequence for BERT.\n",
    "EXPERIMENT_CONFIG['BERT_MAX_SEQ_LENGTH'] = 128\n",
    "\n",
    "# Optimizer configuration\n",
    "EXPERIMENT_CONFIG['SERVER_LEARNING_RATE'] = 1.0 # Server learning rate.\n",
    "EXPERIMENT_CONFIG['CLIENT_LEARNING_RATE'] = 3e-5 # Client learning rate\n",
    "\n",
    "EXPERIMENT_CONFIG['CENTRALIZED_LEARNING_RATE'] = EXPERIMENT_CONFIG['SERVER_LEARNING_RATE'] * EXPERIMENT_CONFIG['CLIENT_LEARNING_RATE']\n",
    "\n",
    "# Client dataset setting\n",
    "EXPERIMENT_CONFIG['TRAIN_NUM_CLIENT_LIMIT'] = 100\n",
    "EXPERIMENT_CONFIG['TEST_NUM_CLIENT_LIMIT'] = 100\n",
    "\n",
    "# Path to save trained weights and logs\n",
    "EXPERIMENT_CONFIG['RESULTS_DIRECTORY'] = os.path.join(\n",
    "    '.', 'results',\n",
    "    'mobilebert_mlm_stackoverflow_centralized',\n",
    "    datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    ")\n",
    "\n",
    "EXPERIMENT_CONFIG['RESULTS_LOG'] = os.path.join(EXPERIMENT_CONFIG['RESULTS_DIRECTORY'], \"logs\")\n",
    "EXPERIMENT_CONFIG['RESULTS_MODEL'] = os.path.join(EXPERIMENT_CONFIG['RESULTS_DIRECTORY'], \"model\")\n",
    "EXPERIMENT_CONFIG['RESULTS_CONFIG'] = os.path.join(EXPERIMENT_CONFIG['RESULTS_DIRECTORY'], \"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump all the configuration into a json file\n",
    "pathlib.Path(EXPERIMENT_CONFIG['RESULTS_CONFIG']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(EXPERIMENT_CONFIG['RESULTS_CONFIG'], \"config.json\"), 'w') as config_file:\n",
    "    json.dump(EXPERIMENT_CONFIG, config_file, indent=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-tHcHX0FQvz"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuI6ktSIbCjk"
   },
   "source": [
    "### Load the Stackoverflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cVkK1BV9FQv3"
   },
   "outputs": [],
   "source": [
    "train_client_data = tff.python.simulation.hdf5_client_data.HDF5ClientData(\n",
    "    os.path.join('.', 'tff_cache', 'datasets', 'stackoverflow_train.h5'))\n",
    "held_out_client_data = tff.python.simulation.hdf5_client_data.HDF5ClientData(\n",
    "    os.path.join('.', 'tff_cache', 'datasets', 'stackoverflow_held_out.h5'))\n",
    "test_client_data = tff.python.simulation.hdf5_client_data.HDF5ClientData(\n",
    "    os.path.join('.', 'tff_cache', 'datasets', 'stackoverflow_test.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNYlFQJ3Wt1O"
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ZXmJYQbeFQwG"
   },
   "outputs": [],
   "source": [
    "mobilebert_tokenizer = transformers.MobileBertTokenizer.from_pretrained(\n",
    "    'google/mobilebert-uncased', cache_dir='./transformers_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8c7S9s9qRlsi"
   },
   "outputs": [],
   "source": [
    "# Imitate transformers tokenizer with TF.Text Tokenizer\n",
    "tokenizer_tf_text, vocab_lookup_table, special_ids_mask_table = datasets.preprocessing_for_bert.convert_huggingface_tokenizer(mobilebert_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sfMNvpmFQwW"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oIOw1zG1RfnU"
   },
   "outputs": [],
   "source": [
    "def check_empty_snippet(x):\n",
    "    return tf.strings.length(x['tokens']) > 0\n",
    "\n",
    "def tokenizer_and_mask_wrapped(x):\n",
    "\n",
    "    masked, labels = datasets.preprocessing_for_bert.tokenize_and_mask(tf.reshape(x['tokens'], shape=[1]),\n",
    "                                                                       max_seq_length=EXPERIMENT_CONFIG['BERT_MAX_SEQ_LENGTH'],\n",
    "                                                                       bert_tokenizer_tf_text=tokenizer_tf_text,\n",
    "                                                                       vocab_lookup_table=vocab_lookup_table,\n",
    "                                                                       special_ids_mask_table=special_ids_mask_table,\n",
    "                                                                       cls_token_id=mobilebert_tokenizer.cls_token_id,\n",
    "                                                                       sep_token_id=mobilebert_tokenizer.sep_token_id,\n",
    "                                                                       pad_token_id=mobilebert_tokenizer.pad_token_id,\n",
    "                                                                       mask_token_id=mobilebert_tokenizer.mask_token_id)\n",
    "\n",
    "    return (masked, labels)\n",
    "\n",
    "def preprocess_for_train(train_dataset):\n",
    "    return (\n",
    "        train_dataset\n",
    "        # Tokenize each samples using MobileBERT tokenizer\n",
    "        .map(tokenizer_and_mask_wrapped, num_parallel_calls=tf.data.experimental.AUTOTUNE, deterministic=False)\n",
    "        # Shuffle\n",
    "        .shuffle(100000)\n",
    "        # Form minibatches\n",
    "        # Use drop_remainder=True to force the batch size to be exactly BATCH_SIZE\n",
    "        # and make the shape **exactly** (BATCH_SIZE, SEQ_LENGTH)\n",
    "        .batch(EXPERIMENT_CONFIG['BATCH_SIZE'], drop_remainder=True)\n",
    "        # Repeat to make each client train multiple epochs\n",
    "        .repeat(count=EXPERIMENT_CONFIG['CENTRALIZED_EPOCHS'])\n",
    "    )\n",
    "    \n",
    "def preprocess_for_test(test_dataset):\n",
    "    return (\n",
    "        test_dataset\n",
    "        # Tokenize each samples using MobileBERT tokenizer\n",
    "        .map(tokenizer_and_mask_wrapped, num_parallel_calls=tf.data.experimental.AUTOTUNE, deterministic=False)\n",
    "        # Shuffle\n",
    "        .shuffle(100000)\n",
    "        # Form minibatches\n",
    "        # Use drop_remainder=True to force the batch size to be exactly TEST_BATCH_SIZE\n",
    "        # and make the shape **exactly** (TEST_BATCH_SIZE, SEQ_LENGTH)\n",
    "        .batch(EXPERIMENT_CONFIG['TEST_BATCH_SIZE'], drop_remainder=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the stackoverflow dataset is pretty large, we randomly select TRAIN_NUM_CLIENT_LIMIT number of clients.\n",
    "all_train_client_ids = train_client_data.client_ids\n",
    "\n",
    "random.shuffle(all_train_client_ids)\n",
    "\n",
    "if EXPERIMENT_CONFIG['TRAIN_NUM_CLIENT_LIMIT'] > 0:\n",
    "    selected_train_client_ids = all_train_client_ids[0:EXPERIMENT_CONFIG['TRAIN_NUM_CLIENT_LIMIT']]\n",
    "else:\n",
    "    selected_train_client_ids = all_train_client_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "meLGsVyoiW7u"
   },
   "outputs": [],
   "source": [
    "train_client_data_all_merged = train_client_data.create_tf_dataset_for_client(\n",
    "    selected_train_client_ids[0]).filter(check_empty_snippet)\n",
    "\n",
    "if len(selected_train_client_ids) > 1:\n",
    "    for i in range(1, len(selected_train_client_ids)):\n",
    "        train_client_data_all_merged = train_client_data_all_merged.concatenate(\n",
    "            train_client_data.create_tf_dataset_for_client(selected_train_client_ids[i]).filter(check_empty_snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67997,
     "status": "ok",
     "timestamp": 1605971415116,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "K-YFkR4CDhhC",
    "outputId": "d89d9a87-b3ec-4bf2-8a27-2a3a304bf801"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/BERTerated/datasets/preprocessing_for_bert.py:76: Bernoulli.__init__ (from tensorflow.python.ops.distributions.bernoulli) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/BERTerated/datasets/preprocessing_for_bert.py:76: Bernoulli.__init__ (from tensorflow.python.ops.distributions.bernoulli) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/bernoulli.py:97: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/bernoulli.py:97: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "train_client_data_all_merged = preprocess_for_train(train_client_data_all_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67989,
     "status": "ok",
     "timestamp": 1605971415121,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "YohjkEIZEJ__",
    "outputId": "8a62923a-cde6-4852-9fa5-c6dced6541b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(16, 128), dtype=tf.int32, name=None), TensorSpec(shape=(16, 128), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "print(train_client_data_all_merged.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the stackoverflow dataset is pretty large, we randomly select TEST_NUM_CLIENT_LIMIT number of clients.\n",
    "all_test_client_ids = test_client_data.client_ids\n",
    "\n",
    "random.shuffle(all_test_client_ids)\n",
    "\n",
    "if EXPERIMENT_CONFIG['TEST_NUM_CLIENT_LIMIT'] > 0:\n",
    "    selected_test_client_ids = all_test_client_ids[0:EXPERIMENT_CONFIG['TEST_NUM_CLIENT_LIMIT']]\n",
    "else:\n",
    "    selected_test_client_ids = all_test_client_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-X8beaHakOge"
   },
   "outputs": [],
   "source": [
    "test_client_data_all_merged = test_client_data.create_tf_dataset_for_client(\n",
    "    selected_test_client_ids[0]).filter(check_empty_snippet)\n",
    "\n",
    "if len(selected_test_client_ids) > 1:\n",
    "    for i in range(1, len(selected_test_client_ids)):\n",
    "        test_client_data_all_merged = test_client_data_all_merged.concatenate(\n",
    "            test_client_data.create_tf_dataset_for_client(selected_test_client_ids[i]).filter(check_empty_snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Wj_jUe1MnVpx"
   },
   "outputs": [],
   "source": [
    "test_client_data_all_merged = preprocess_for_test(test_client_data_all_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(32, 128), dtype=tf.int32, name=None), TensorSpec(shape=(32, 128), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "print(test_client_data_all_merged.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_o5NZpuzFQw7"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84609,
     "status": "ok",
     "timestamp": 1605971431782,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "kfTDbXNpnr1A",
    "outputId": "ade5e7df-9939-4c04-ef80-51e5e15aca7b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFMobileBertForPreTraining.\n",
      "\n",
      "All the layers of TFMobileBertForPreTraining were initialized from the model checkpoint at google/mobilebert-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMobileBertForPreTraining for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "mobilebert_model = transformers.TFMobileBertForPreTraining.from_pretrained(\n",
    "    'google/mobilebert-uncased', cache_dir='./transformers_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84600,
     "status": "ok",
     "timestamp": 1605971431786,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "4xrKChglOi9J",
    "outputId": "7e1fde9e-79c9-4acb-cfc9-86fdef025092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileBertConfig {\n",
      "  \"_name_or_path\": \"google/mobilebert-uncased\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_activation\": false,\n",
      "  \"embedding_size\": 128,\n",
      "  \"hidden_act\": \"relu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"intra_bottleneck_size\": 128,\n",
      "  \"key_query_shared_bottleneck\": true,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"mobilebert\",\n",
      "  \"normalization_type\": \"no_norm\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_feedforward_networks\": 4,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"trigram_input\": true,\n",
      "  \"true_hidden_size\": 128,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bottleneck\": true,\n",
      "  \"use_bottleneck_attention\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mobilebert_model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "FDOF1EcWrOVJ"
   },
   "outputs": [],
   "source": [
    "# Due to the limitations with Keras subclasses, we can only use the main layer part from pretrained models\n",
    "# and add output heads by ourselves\n",
    "mobilebert_keras_converted = utils.convert_huggingface_mlm_to_keras(\n",
    "    huggingface_model=mobilebert_model,\n",
    "    max_seq_length=EXPERIMENT_CONFIG['BERT_MAX_SEQ_LENGTH'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 93688,
     "status": "ok",
     "timestamp": 1605971440890,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "uTbzF5dzxKeL",
    "outputId": "4bf41bc1-3d17-4812-e579-560a7556db31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "mobilebert (TFMobileBertMain ((None, 128, 512), (None, 24581888  \n",
      "_________________________________________________________________\n",
      "standalone_tf_mobile_bert_ml (None, 128, 30522)        15921466  \n",
      "=================================================================\n",
      "Total params: 40,503,354\n",
      "Trainable params: 40,503,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobilebert_keras_converted.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qM6T_Mp8FQxQ"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4poIAcZ4QUNs"
   },
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 822
    },
    "executionInfo": {
     "elapsed": 6431,
     "status": "ok",
     "timestamp": 1605972334334,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "_mZQwAehX2t3",
    "outputId": "df09f538-3e9a-4d45-b59f-2f7708b16195"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c0852896d7439289\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c0852896d7439289\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir {EXPERIMENT_CONFIG['RESULTS_LOG']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXwPdo-_Qrsk"
   },
   "source": [
    "### Training setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "qWGC89ZVWt1c"
   },
   "outputs": [],
   "source": [
    "mobilebert_keras_converted.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=EXPERIMENT_CONFIG['CENTRALIZED_LEARNING_RATE']),\n",
    "    loss=utils.MaskedLMCrossEntropy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CDsVTWMeNJm1"
   },
   "outputs": [],
   "source": [
    "# TensorBoard Callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=EXPERIMENT_CONFIG['RESULTS_LOG'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oqCXFc7gFQxl",
    "outputId": "847f79d7-dc12-45e8-e3f2-862062882f42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "      1/Unknown - 0s 237us/step - loss: 5.5540WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7029/7029 [==============================] - 1071s 152ms/step - loss: 2.8217\n",
      "Epoch 2/3\n",
      "7029/7029 [==============================] - 1072s 153ms/step - loss: 2.5360\n",
      "Epoch 3/3\n",
      "7029/7029 [==============================] - 1076s 153ms/step - loss: 2.3538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2b802e2470>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilebert_keras_converted.fit(\n",
    "    train_client_data_all_merged,\n",
    "    epochs=EXPERIMENT_CONFIG['CENTRALIZED_EPOCHS'],\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNsibFUnbFHv"
   },
   "source": [
    "### Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "kkqxlRhzvLPl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./results/mobilebert_mlm_stackoverflow_centralized/20201121-212259/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./results/mobilebert_mlm_stackoverflow_centralized/20201121-212259/model/assets\n"
     ]
    }
   ],
   "source": [
    "mobilebert_keras_converted.save(EXPERIMENT_CONFIG['RESULTS_MODEL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pw35YbQVbAvT"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we need to evaluate with the saved model\n",
    "# mobilebert_keras_converted_load = tf.keras.models.load_model(\n",
    "#    os.path.join(RESULTS_DIRECTORY, 'model'),\n",
    "#    custom_objects={'MaskedLMCrossEntropy': utils.MaskedLMCrossEntropy}\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "F9MGEXE0FB3F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - 18s 78ms/step - loss: 3.0124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.012441635131836"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilebert_keras_converted.evaluate(\n",
    "    test_client_data_all_merged,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mobilebert_mlm_shakespeare_centralized.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
