{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning MobileBERT with Federated Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020, The TensorFlow Federated Authors.\n",
    "# Copyright 2020, Ronald Seoh\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Google Colab\n",
    "use_colab = True\n",
    "\n",
    "# Is this notebook running on Colab?\n",
    "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
    "# should be available in this environment\n",
    "\n",
    "# Previous version used importlib, but we could do the same thing with\n",
    "# just attempting to import google.colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab_available = True\n",
    "except:\n",
    "    colab_available = False\n",
    "\n",
    "if use_colab and colab_available:\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # If there's a package I need to install separately, do it here\n",
    "    !pip install pyro-ppl\n",
    "\n",
    "    # cd to the appropriate working directory under my Google Drive\n",
    "    %cd 'drive/My Drive/Colab Notebooks/BERTerated'\n",
    "    \n",
    "    # List the directory contents\n",
    "    !ls\n",
    "\n",
    "# IPython reloading magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Random seeds\n",
    "# Based on https://pytorch.org/docs/stable/notes/randomness.html\n",
    "random_seed = 692"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-federated-nightly==0.16.1.dev20201021 in /home/se22/miniconda3/envs/idp-tff-py36/lib/python3.6/site-packages (0.16.1.dev20201021)\n",
      "Requirement already satisfied: transformers==3.4.0 in /home/se22/miniconda3/envs/idp-tff-py36/lib/python3.6/site-packages (3.4.0)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /home/se22/miniconda3/envs/idp-tff-py36/lib/python3.6/site-packages (from tensorflow-federated-nightly==0.16.1.dev20201021) (0.1.5)\n",
      "Requirement already satisfied: retrying~=1.3.3 in /home/se22/miniconda3/envs/idp-tff-py36/lib/python3.6/site-packages (from tensorflow-federated-nightly==0.16.1.dev20201021) (1.3.3)\n",
      "Collecting tensorflow-model-optimization~=0.4.0 (from tensorflow-federated-nightly==0.16.1.dev20201021)\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/cc/4b0831f492396f03a4563cc749ad94cbf7af986aaa7a7d89e5979029ce5c/tensorflow_model_optimization-0.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: portpicker~=1.3.1 in /home/se22/miniconda3/envs/idp-tff-py36/lib/python3.6/site-packages (from tensorflow-federated-nightly==0.16.1.dev20201021) (1.3.1)\n",
      "Requirement already satisfied: absl-py~=0.9.0 in /home/se22/miniconda3/envs/idp-tff-py36/lib/python3.6/site-packages (from tensorflow-federated-nightly==0.16.1.dev20201021) (0.9.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /home/se22/miniconda3/envs/idp-tff-py36/lib/python3.6/site-packages (from tensorflow-federated-nightly==0.16.1.dev20201021) (2.10.0)\n",
      "Requirement already satisfied: grpcio~=1.29.0 in /home/se22/miniconda3/envs/idp-tff-py36/lib/python3.6/site-packages (from tensorflow-federated-nightly==0.16.1.dev20201021) (1.29.0)\n",
      "Requirement already satisfied: cachetools~=3.1.1 in /home/se22/miniconda3/envs/idp-tff-py36/lib/python3.6/site-packages (from tensorflow-federated-nightly==0.16.1.dev20201021) (3.1.1)\n",
      "Collecting attrs~=19.3.0 (from tensorflow-federated-nightly==0.16.1.dev20201021)\n",
      "  Using cached https://files.pythonhosted.org/packages/a2/db/4313ab3be961f7a763066401fb77f7748373b6094076ae2bda2806988af6/attrs-19.3.0-py2.py3-none-any.whl\n",
      "Collecting numpy~=1.18.4 (from tensorflow-federated-nightly==0.16.1.dev20201021)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/a9/b1bc4c935ed063766bce7d3e8c7b20bd52e515ff1c732b02caacf7918e5a/numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
      "\u001b[K     |█████████████████▋              | 11.1MB 3.3MB/s eta 0:00:03^C  |█                               | 614kB 1.9MB/s eta 0:00:11     |██▌                             | 1.5MB 1.9MB/s eta 0:00:10     |████████▉                       | 5.5MB 2.9MB/s eta 0:00:05     |█████████▍                      | 5.9MB 2.9MB/s eta 0:00:05     |██████████████▊                 | 9.2MB 3.3MB/s eta 0:00:04\n",
      "\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install tensorflow-federated-nightly==0.16.1.dev20201021 transformers==3.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/se22/miniconda3/envs/idp-tff-py36/lib/python3.6/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.4.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.4.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'Hello, World!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import transformers\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import simple_fedavg_tf\n",
    "import simple_fedavg_tff\n",
    "\n",
    "# Random seed settings\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "# Test the TFF is working:\n",
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.9 |Intel Corporation| (default, Sep 11 2019, 16:40:08) \n",
      "[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]\n",
      "NumPy version: 1.17.0\n",
      "TensorFlow version: 2.4.0\n",
      "TensorFlow Federated version: 0.16.1\n",
      "Transformers version: 3.4.0\n"
     ]
    }
   ],
   "source": [
    "# Print version information\n",
    "print(\"Python version: \" + sys.version)\n",
    "print(\"NumPy version: \" + np.__version__)\n",
    "print(\"TensorFlow version: \" + tf.__version__)\n",
    "print(\"TensorFlow Federated version: \" + tff.__version__)\n",
    "print(\"Transformers version: \" + transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rounds = 256 # Number of total training rounds\n",
    "rounds_per_eval = 1 # How often to evaluate\n",
    "train_clients_per_round = 2 # How many clients to sample per round.\n",
    "client_epochs_per_round = 1 # Number of epochs in the client to take per round.\n",
    "batch_size = 20 # Batch size used on the client.\n",
    "test_batch_size = 100 # Minibatch size of test data.\n",
    "\n",
    "# Optimizer configuration\n",
    "server_learning_rate = 1.0 # Server learning rate.\n",
    "fclient_learning_rate = 0.1 # Client learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = tff.simulation.datasets.shakespeare.load_data(cache_dir='./tff_shakespeare_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilebert_tokenizer = transformers.MobileBertTokenizer.from_pretrained(\n",
    "    'google/mobilebert-uncased', cache_dir='./transformers_cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codes based on the tips from\n",
    "# https://www.tensorflow.org/federated/tutorials/federated_learning_for_text_generation\n",
    "# https://stackoverflow.com/questions/61555097/mapping-text-data-through-huggingface-tokenizer\n",
    "def tokenize_snippets(x):\n",
    "    tokenized = mobilebert_tokenizer.encode(\n",
    "        tf.compat.as_str(x.numpy()), add_special_tokens=True, return_tensors='tf')\n",
    "    \n",
    "    return tokenized\n",
    "\n",
    "def tf_tokenize(x):\n",
    "    tokenized = tf.py_function(func=tokenize_snippets, inp = [x['snippets']], Tout=[tf.int32])\n",
    "\n",
    "    return tokenized\n",
    "\n",
    "def preprocess(dataset):\n",
    "    return (\n",
    "        # Map ASCII chars to int64 indexes using the vocab\n",
    "        dataset.map(tf_tokenize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=<unknown>, dtype=tf.int32, name=None),)\n"
     ]
    }
   ],
   "source": [
    "raw_example_dataset = train_data.create_tf_dataset_for_client('THE_TRAGEDY_OF_KING_LEAR_KING')\n",
    "example_dataset = preprocess(raw_example_dataset)\n",
    "print(example_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/mobilebert-uncased were not used when initializing TFMobileBertForMaskedLM: ['predictions___cls', 'seq_relationship___cls']\n",
      "- This IS expected if you are initializing TFMobileBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFMobileBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFMobileBertForMaskedLM were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['mlm___cls']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "def tff_model_fn():\n",
    "    \"\"\"Constructs a fully initialized model for use in federated averaging.\"\"\"\n",
    "    keras_model = transformers.TFMobileBertForMaskedLM.from_pretrained(\n",
    "        'google/mobilebert-uncased', cache_dir='./transformers_cache')\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    return simple_fedavg_tf.KerasModelWrapper(keras_model, example_dataset.element_spec, loss)\n",
    "\n",
    "model = tff_model_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterative_process = simple_fedavg_tff.build_federated_averaging_process(\n",
    "    tff_model_fn, server_optimizer_fn, client_optimizer_fn)\n",
    "\n",
    "server_state = iterative_process.initialize()\n",
    "\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for round_num in range(total_rounds):\n",
    "    sampled_clients = np.random.choice(\n",
    "        train_data.client_ids,\n",
    "        size=train_clients_per_round,\n",
    "        replace=False)\n",
    "\n",
    "    sampled_train_data = [\n",
    "        train_data.create_tf_dataset_for_client(client)\n",
    "        for client in sampled_clients\n",
    "    ]\n",
    "\n",
    "    server_state, train_metrics = iterative_process.next(server_state, sampled_train_data)\n",
    "\n",
    "    print(f'Round {round_num} training loss: {train_metrics}')\n",
    "\n",
    "    if round_num % rounds_per_eval == 0:\n",
    "        model.from_weights(server_state.model_weights)\n",
    "\n",
    "        accuracy = simple_fedavg_tf.keras_evaluate(model.keras_model, test_data, metric)\n",
    "\n",
    "        print(f'Round {round_num} validation accuracy: {accuracy * 100.0}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
