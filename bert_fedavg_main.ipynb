{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6qruq9ZFQsN"
   },
   "source": [
    "# Fine-Tuning MobileBERT with Federated Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-AgOn_qCFQsk"
   },
   "outputs": [],
   "source": [
    "# Copyright 2020, The TensorFlow Federated Authors.\n",
    "# Copyright 2020, Ronald Seoh\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zUGmvEbFQts"
   },
   "source": [
    "## Google Colab settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30099,
     "status": "ok",
     "timestamp": 1605021417752,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "_1nBG9qaFQt9",
    "outputId": "d1b3e8bb-1b88-4962-9e86-7b63dc3c0623"
   },
   "outputs": [],
   "source": [
    "# Use Google Colab\n",
    "use_colab = True\n",
    "\n",
    "# Is this notebook running on Colab?\n",
    "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
    "# should be available in this environment\n",
    "\n",
    "# Previous version used importlib, but we could do the same thing with\n",
    "# just attempting to import google.colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab_available = True\n",
    "except:\n",
    "    colab_available = False\n",
    "\n",
    "if use_colab and colab_available:\n",
    "    # If there's a package I need to install separately, do it here\n",
    "    !pip install tensorflow-federated==0.17.0 transformers==3.4.0\n",
    "\n",
    "    # Mount Google Drive root directory\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # cd to the appropriate working directory under my Google Drive\n",
    "    %cd 'drive/My Drive/Colab Notebooks/BERTerated'\n",
    "    \n",
    "    # List the directory contents\n",
    "    !ls\n",
    "\n",
    "# IPython reloading magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F16eB2w-FQuw"
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14478,
     "status": "ok",
     "timestamp": 1605021465390,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "k_SnruV2FQu0",
    "outputId": "9c17aed8-dd25-4e0b-bdfb-a6543289cdf4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import transformers\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import simple_fedavg_tf\n",
    "import simple_fedavg_tff\n",
    "import utils\n",
    "\n",
    "# Random seed settings\n",
    "random_seed = 692\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "# Tensorflow GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Test the TFF is working:\n",
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1141,
     "status": "ok",
     "timestamp": 1605021471751,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "FHYxELiQFQvI",
    "outputId": "9d80bedb-9d43-42ce-b6f0-2aa588e23bdf"
   },
   "outputs": [],
   "source": [
    "# Print version information\n",
    "print(\"Python version: \" + sys.version)\n",
    "print(\"NumPy version: \" + np.__version__)\n",
    "print(\"TensorFlow version: \" + tf.__version__)\n",
    "print(\"TensorFlow Federated version: \" + tff.__version__)\n",
    "print(\"Transformers version: \" + transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYXMEboAFQvd"
   },
   "source": [
    "## Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1344,
     "status": "ok",
     "timestamp": 1605021476693,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "M071lqOQFQvi"
   },
   "outputs": [],
   "source": [
    "TOTAL_ROUNDS = 256 # Number of total training rounds\n",
    "ROUNDS_PER_EVAL = 1 # How often to evaluate\n",
    "TRAIN_CLIENTS_PER_ROUND = 2 # How many clients to sample per round.\n",
    "CLIENT_EPOCHS_PER_ROUND = 1 # Number of epochs in the client to take per round.\n",
    "BATCH_SIZE = 20 # Batch size used on the client.\n",
    "BUFFER_SIZE = 1000  # For dataset shuffling\n",
    "TEST_BATCH_SIZE = 100 # Minibatch size of test data.\n",
    "SEQ_LENGTH = 512 # Maximum length of input token sequence for BERT.\n",
    "\n",
    "# Optimizer configuration\n",
    "SERVER_LEARNING_RATE = 1.0 # Server learning rate.\n",
    "CLIENT_LEARNING_RATE = 0.1 # Client learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-tHcHX0FQvz"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "executionInfo": {
     "elapsed": 864174,
     "status": "error",
     "timestamp": 1605024213219,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "cVkK1BV9FQv3",
    "outputId": "22435127-e645-4900-c632-d86f29cdb9c5"
   },
   "outputs": [],
   "source": [
    "# Originally tff.simulation.datasets.stackoverflow.load_data(cache_dir='./tff_cache')\n",
    "# Uncomment below to download the data files.\n",
    "#!curl -o ./tff_cache/datasets/stackoverflow.tar.bz2 https://storage.googleapis.com/tff-datasets-public/stackoverflow.tar.bz2\n",
    "#!tar xvfj ./tff_cache/datasets/stackoverflow.tar.bz2 -C ./tff_cache/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20052,
     "status": "ok",
     "timestamp": 1605025997120,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "8R0IevYM-Afj"
   },
   "outputs": [],
   "source": [
    "train_client_data = tff.python.simulation.hdf5_client_data.HDF5ClientData(\n",
    "    os.path.join('.', 'tff_cache', 'datasets', 'stackoverflow_train.h5'))\n",
    "held_out_client_data = tff.python.simulation.hdf5_client_data.HDF5ClientData(\n",
    "    os.path.join('.', 'tff_cache', 'datasets', 'stackoverflow_held_out.h5'))\n",
    "test_client_data = tff.python.simulation.hdf5_client_data.HDF5ClientData(\n",
    "    os.path.join('.', 'tff_cache', 'datasets', 'stackoverflow_test.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXmJYQbeFQwG"
   },
   "outputs": [],
   "source": [
    "mobilebert_tokenizer = transformers.MobileBertTokenizer.from_pretrained(\n",
    "    'google/mobilebert-uncased', cache_dir='./transformers_cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sfMNvpmFQwW"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vALOJEukFQwZ"
   },
   "outputs": [],
   "source": [
    "# Codes based on the tips from\n",
    "# https://www.tensorflow.org/federated/tutorials/federated_learning_for_text_generation\n",
    "# https://stackoverflow.com/questions/61555097/mapping-text-data-through-huggingface-tokenizer\n",
    "# https://stackoverflow.com/questions/61022109/how-to-return-a-dictionary-of-tensors-from-tf-py-function\n",
    "# https://stackoverflow.com/questions/42590431/output-from-tensorflow-py-func-has-unknown-rank-shape?noredirect=1\n",
    "def tokenize_and_mask(x):\n",
    "    # 'tokenized' is a PyTorch tensor because Transformers collator only accepts PyTorch tensors\n",
    "    tokenized = mobilebert_tokenizer.encode(\n",
    "        tf.compat.as_str(x.numpy()),\n",
    "        add_special_tokens=True, padding='max_length', max_length=SEQ_LENGTH,\n",
    "        return_tensors='tf')\n",
    "    \n",
    "    masked, labels = utils.get_masked_input_and_labels(tokenized, mobilebert_tokenizer)\n",
    "    \n",
    "    return masked, labels\n",
    "\n",
    "def tf_tokenize(x):\n",
    "    masked, labels = tf.py_function(\n",
    "        func=tokenize_and_mask, inp=[x['tokens']], Tout=[tf.int32, tf.int32])\n",
    "\n",
    "    masked = tf.squeeze(masked)\n",
    "    labels = tf.squeeze(labels)\n",
    "\n",
    "    # Manually settting the shape here so that TensorFlow graph\n",
    "    # could know the sizes in advnace\n",
    "    masked.set_shape(SEQ_LENGTH)\n",
    "    labels.set_shape(SEQ_LENGTH)\n",
    "\n",
    "    return masked, labels\n",
    "\n",
    "def preprocess(dataset):\n",
    "    return (\n",
    "        # Tokenize each samples using MobileBERT tokenizer\n",
    "        dataset.map(tf_tokenize)\n",
    "        # Shuffle and form minibatches\n",
    "        # Use drop_remainder=True to force the batch size to be exactly BATCH_SIZE\n",
    "        # and make the shape **exactly** (BATCH_SIZE, SEQ_LENGTH)\n",
    "        .shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 793,
     "status": "ok",
     "timestamp": 1604945995028,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "b8NzsgjFFQwp",
    "outputId": "083cff1f-8dd9-473f-f08c-147cfb92ee86"
   },
   "outputs": [],
   "source": [
    "# Create a test client dataset, just to get the element_spec info\n",
    "raw_example_dataset = heldout_client_data.create_tf_dataset_for_client('00045530')\n",
    "example_dataset = preprocess(raw_example_dataset)\n",
    "print(example_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_o5NZpuzFQw7"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7857,
     "status": "ok",
     "timestamp": 1604946005123,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "2kRecwJPFQw-",
    "outputId": "b77794ae-738e-44d7-95b5-d50871ef3edb"
   },
   "outputs": [],
   "source": [
    "def tff_model_fn():\n",
    "    \"\"\"Constructs a fully initialized model for use in federated averaging.\"\"\"\n",
    "    keras_model = transformers.TFMobileBertForMaskedLM.from_pretrained(\n",
    "        'google/mobilebert-uncased', cache_dir='./transformers_cache')\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    return simple_fedavg_tf.KerasModelWrapper(keras_model, example_dataset.element_spec, loss)\n",
    "\n",
    "model = tff_model_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qM6T_Mp8FQxQ"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXwPdo-_Qrsk"
   },
   "source": [
    "### Training setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPNLTNLWQwDX"
   },
   "outputs": [],
   "source": [
    "def server_optimizer_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=SERVER_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JEPK0AlzujvZ"
   },
   "outputs": [],
   "source": [
    "def client_optimizer_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=CLIENT_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 100921,
     "status": "error",
     "timestamp": 1604946114991,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "qBzCiCkWFQxW",
    "outputId": "24852d80-16bc-4d3d-d73a-dfe2777962d4"
   },
   "outputs": [],
   "source": [
    "iterative_process = simple_fedavg_tff.build_federated_averaging_process(\n",
    "    tff_model_fn, server_optimizer_fn, client_optimizer_fn)\n",
    "\n",
    "server_state = iterative_process.initialize()\n",
    "\n",
    "metric = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqCXFc7gFQxl"
   },
   "outputs": [],
   "source": [
    "for round_num in range(TOTAL_ROUNDS):\n",
    "    sampled_clients = np.random.choice(\n",
    "        train_data.client_ids,\n",
    "        size=TRAIN_CLIENTS_PER_ROUND,\n",
    "        replace=False)\n",
    "\n",
    "    sampled_train_data = [\n",
    "        train_data.create_tf_dataset_for_client(client)\n",
    "        for client in sampled_clients\n",
    "    ]\n",
    "\n",
    "    server_state, train_metrics = iterative_process.next(server_state, sampled_train_data)\n",
    "\n",
    "    print(f'Round {round_num} training loss: {train_metrics}')\n",
    "\n",
    "    if round_num % rounds_per_eval == 0:\n",
    "        model.from_weights(server_state.model_weights)\n",
    "\n",
    "        perplexity_validation = simple_fedavg_tf.keras_evaluate(model.keras_model, test_data, metric)\n",
    "\n",
    "        print(f'Round {round_num} validation perplexity: {perplexity_validation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zR6ItAlWFQx2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bert_fedavg_main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
